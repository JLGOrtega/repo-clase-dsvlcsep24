{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab05324d-0566-4b81-9cfa-10ee3ef514af",
   "metadata": {},
   "source": [
    "# Web Scraping Workshop with Python Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce30b6-2af1-4c47-9db5-c3e60e5a5d98",
   "metadata": {},
   "source": [
    "There are three steps required to successfully scrape a website:\n",
    "\n",
    "1) **Retreiving the data**\n",
    "\n",
    "    When you enter a URL into your browser and load a website on your computer, the contents of and the structure of the webpage is downloaded to your computer and displayed by your browser. This data is stored in an *HTML* file. To successfully web scrape a webpage, we must get access to this HTML data so that we can further analyze its contents.\n",
    " \n",
    "2) **Parsing the data**\n",
    "\n",
    "    How that you have access to a website's HTML data, you now have to make sense of this data. Oftentimes, a big part of this step is figuring out which components of the HTML you need -- and which ones you don't. This is often the hardest and most tedious part of web scraping, but this is where the magic really happens.\n",
    "    \n",
    "3) **Using the data**\n",
    "\n",
    "    Congratulations! Now that you have you data, you can now do something cool with it. You can analyze this data, gain new insights and knowledge, even work on your very own data science app with this data as well (with proper attribution, of course!)\n",
    "    \n",
    "Here, you will learn the basics of creating your own web scraping script using the `BeautifulSoup` and `requests` package for the Python programming language. You will learn how to perform all three tasks of web scraping - retreiving the raw source HTML from a webpage, parsing that data to gain valuable data and knowledge, and storing that data to develop new insights or work on your very own data science app. We will also discuss how web scraping has been used in technologies and software commonly used today, as well as the potential ethical implications of the practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d8bd72-6491-4078-b2fe-6a29bf79db19",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737005f-2749-443b-ad2f-82b048c04aea",
   "metadata": {},
   "source": [
    "This workshop heavily uses the `requests` and `beautifulsoup4` package for Python. To install this, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b9370-0c9d-4c85-b467-14668f6e5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65940030-ccd0-4efb-96bc-970d1c25b46d",
   "metadata": {},
   "source": [
    "Now that you have installed the `requests` and `beautifulsoup4` package, import them below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83281f9-3d99-4c1b-b240-970aa6ab1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `requests` package\n",
    "import requests\n",
    "\n",
    "# Import `BeautifulSoup` from the `bs4` package\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b84cbe-4292-4aae-b22e-1454e0e98462",
   "metadata": {},
   "source": [
    "As you noticed above, `beautifulsoup4` is abbreviated as `bs4`. Then from there, we can import `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f60c4b-29f0-49fd-8080-3d91fb22b86c",
   "metadata": {},
   "source": [
    "**Congratulations!** You are now ready to start web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4f8ec-9719-4552-8b6d-32f2195d215e",
   "metadata": {},
   "source": [
    "## Part 1: Retrieving the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c5152-93b8-4257-88aa-d034a8f0e5f0",
   "metadata": {},
   "source": [
    "Remember, when you enter a URL into your browser and load a website on your computer, the contents of and the structure of the webpage is downloaded to your computer and displayed by your browser.\n",
    "\n",
    "This data is stored in an *HTML* file! To successfully web scrape a webpage, we must get access to this HTML data so that we can further analyze its contents.\n",
    "\n",
    "In Python, we can use the `requests` package to download and store the HTML from a URL!\n",
    "\n",
    "Which URL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60dd85-7d2c-4980-bcfe-cd93ac807d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for Professor Eskandarian's course explorer tool:\n",
    "url = \"https://crypto.unc.edu/UNC_classes/fall2023/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c551ae0-72a1-4396-a5de-586559a354c3",
   "metadata": {},
   "source": [
    "Now, we want to fetch the data from this URL! Let's use the `requests.get()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3635a3b-5a2a-414e-884e-8950573e7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from the URL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc1570-58ef-4137-993f-fb9b028f0d0a",
   "metadata": {},
   "source": [
    "As you can see, we received a response! Have you ever heard of the *404 Not Found* error? That is a response as well. 200 means all is well.\n",
    "\n",
    "Now, let's find that HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96758c-c5f2-4314-8431-68f4442810b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find data text (the HTML!) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f879d25-0ca7-41e1-aa8d-ffa8d8f4878f",
   "metadata": {},
   "source": [
    "Wow, that is quite long! Congratulations, you have now completed step 1 -- retrieving the data! But now, how do we make sense of all that gibberish?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418e88e-8119-41da-b621-e2bbcfc2454e",
   "metadata": {},
   "source": [
    "## Part 2: Parsing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48c0d6-e8e2-4a07-9887-3444779abf14",
   "metadata": {},
   "source": [
    "Now that we have the HTML data, we now unleash the full power of `BeautifulSoup` to parse this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86a50e-e23a-460c-af6a-bec4a8f79112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data using the HTML that we extracted using the `html.parser`, and save output to soup.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab3652-0882-45b8-af38-1db3f9062b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now, let's print out the \"prettified\" version of that HTML!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ffbf6-b2e9-44db-8795-8c5f5b854707",
   "metadata": {},
   "source": [
    "`BeautifulSoup` does a lot more than just printing HTML in a nice way. We can now also find specific elements on the webpage!\n",
    "\n",
    "Let's find all of the data for the COMP classes. How? Let's take a look at the HTML.\n",
    "\n",
    "You will find that all of the data is located in the `<table>` element! So, let's try and find that element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a474dac-07b4-43ce-b07e-5cfa83092f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find all table elements on the page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a29cc-5de2-4318-b611-1084fd181789",
   "metadata": {},
   "source": [
    "Great! `soup.find_all()` output a **list** of all of the table elements on our page. In this case, there was only one! So, let's select that table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6fdd4-a8ea-4b17-abbc-69faa633e3c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4f151-e446-44e3-9750-5c67c7083d2c",
   "metadata": {},
   "source": [
    "Just like how we used `find_all()` on the `soup` object, we can also use this on elements too! Let's try and find all of the *rows*, represented by `<tr>` elements, in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e3d40-080b-4bfd-9218-2f4f36b29228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find all rows in the table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1d555-101b-4f84-8103-bf8ca1cefe5b",
   "metadata": {},
   "source": [
    "There are certainly a lot of rows in this table! If you notice, the first row is just column headers, and we do not need that (for now). Also, every other row is taken up by a description for a course, so every course is represented by **two rows**. For now to make things simple, we will not save course descriptions. Therefore when scraping data on courses, we need to look at **every other row!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92273f1-1424-4472-a9bd-f18943eb1072",
   "metadata": {},
   "source": [
    "Let's take a look at one of the rows further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cede260-4772-443a-9cc5-21c314944083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out prettified HTML for row 2 (index 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c947f064-6790-49dd-aead-7ee8c066db3b",
   "metadata": {},
   "source": [
    "You will notice that HTML rows (`<tr>` elements) have elements inside called `<td>` elements, which represents data within the table!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a583fbad-4d3b-4cc7-a26c-35ca7f81c55c",
   "metadata": {},
   "source": [
    "Let's now find all of the `<td>` elements inside of this row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60d447-1faa-4f48-8937-6ce53c27f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all <td> elements in the row\n",
    "\n",
    "# Iterate over all <td> elements and print them out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23bb95-1c31-459b-b389-49f1537b2068",
   "metadata": {},
   "source": [
    "We are almost there! We still have HTML, but one last step will print out nice clean text from our HTML. Let's modify the for loop to just grab the `text` of each of these elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c42e5-f0cc-4be3-8a0e-55e7050c160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all <td> elements and print out their texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44864ee6-4efc-46ea-b9dc-2faca054f6d8",
   "metadata": {},
   "source": [
    "Amazing! We have just cleaned up the data for the first row of the table. We can extend this exact logic now for **every row** of the table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7dd90b-81ea-48c7-9cbf-7ba96d588a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over all rows...\n",
    "    \n",
    "    # Find all <td> elements in the row\n",
    "\n",
    "    # Iterate over all <td> elements and print out their texts\n",
    "        \n",
    "    # Add line break between data for each row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4de35a-f8aa-4b5d-a95e-cca0d1beb9e8",
   "metadata": {},
   "source": [
    "Remember, we wanted *every other row*, so let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a453c987-3903-475f-89fd-f81fcad57979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's use some handy Python list notation:\n",
    "# We can create a subset of list `a` with `a[start_index:end_index:step]`\n",
    "# So, if we want every other row of `rows`, we can say `row[1::2]`\n",
    "#     Note: Remember, we start at index 1 because row 0 is our header rows!\n",
    "#     Note: Leaving end index blank implies we are going until the list ends!\n",
    "\n",
    "# Iterate over every other row...\n",
    "    \n",
    "    # Find all <td> elements in the row\n",
    "\n",
    "    # Iterate over all <td> elements and print out their texts\n",
    "        \n",
    "    # Add line break between data for each row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e9022-c0c8-4046-b029-c403f62dea7b",
   "metadata": {},
   "source": [
    "Almost done! Let's use Python dictionaries (key-value pairs) to associate a **key** (column headings!) with each of the rows' data, then add each of these dictionaries to a final list for all of our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84b8ac2-80b5-4dca-a112-fc6e80c523a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine column headers\n",
    "column_headers = [\"Class Number\", \"Class\", \"Meeting Time\", \"Instructor\", \"Room\", \"Unreserved Enrollment\", \"Reserved Enrollment\", \"Wait List\"]\n",
    "\n",
    "#Create list to store final data\n",
    "\n",
    "# Iterate over every other row...\n",
    "    \n",
    "    # Find all <td> elements in the row\n",
    "\n",
    "    # Iterate over all <td> elements and print out their texts\n",
    "\n",
    "        # Get correct column header for the data\n",
    "\n",
    "        # Store the data in the dictionary\n",
    "\n",
    "        \n",
    "    # Add data to final list    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a651acb-688f-49e6-a24b-a8181b12387c",
   "metadata": {},
   "source": [
    "We now have extracted all of the data we need! Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a2e2b-62a4-4d7a-8706-734911899d66",
   "metadata": {},
   "source": [
    "## Part 3: Using the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18d9656-c6bc-4d2d-ae07-b631b67425eb",
   "metadata": {},
   "source": [
    "Now that we have all of this course data, we can now use it for something cool!\n",
    "\n",
    "Here is an example of the course data in a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16c859-8386-41b3-a624-3b8fbe399b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(\"\"\" YOUR FINAL LIST HERE! \"\"\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3521e01-6a29-4c68-b748-dc1862369769",
   "metadata": {},
   "source": [
    "### ANALYSIS\n",
    "\n",
    "Answer the following questions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 WHAT IS THE MOST USED AND THE MOST UNUSED ROOM DURING THE COURSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 WHAT IS THE INSTRUCTOR THAT IMPARTS MOST CLASES, HOW MANY?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 WHAT IS THE AVERAGE OF SEATS FILLED OF Unreserved Enrollment (MEAN OF SEATSFILLED/TOTALSEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 THE MAJORITY OF LESSONS ARE 1H15' LONG. HOW MANY? \n",
    "# ARE THERE ANY OTHER LESSONS LONGER OR SHORTER? HOW MANY? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f598185",
   "metadata": {},
   "source": [
    "### EXTRA\n",
    "\n",
    "Here you have a list of all the terms available. Create a for loop that extracts the table for all terms. Put all the created tables into a dataframe and create a dictionary where the key is the term and the value its corresponding dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [   \"spring2025\",\n",
    "            \"fall2024\",\n",
    "            \"summerII2024\",\n",
    "            \"summerI2024\",\n",
    "            \"spring2024\",\n",
    "            # \"fall2023\",\n",
    "            \"summerII2023\",\n",
    "            \"summerI2023\",\n",
    "            \"spring2023\",\n",
    "            \"fall2022\",\n",
    "            \"spring2022\"\n",
    "        ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
