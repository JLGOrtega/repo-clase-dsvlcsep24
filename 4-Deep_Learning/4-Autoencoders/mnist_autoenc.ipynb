{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will answer some common questions about autoencoders, and we will cover code examples of the following models:\n",
    "\n",
    "- a simple autoencoder based on a fully-connected layer\n",
    "- a sparse autoencoder\n",
    "- a deep fully-connected autoencoder\n",
    "- a deep convolutional autoencoder\n",
    "- an image denoising model\n",
    "- a sequence-to-sequence autoencoder\n",
    "- a variational autoencoder\n",
    "\n",
    "Note: all code examples have been updated to the Keras 2.0 API on March 14, 2017. You will need Keras version 2.0.0 or higher to run them.\n",
    "\n",
    "## What are autoencoders?\n",
    "Autoencoder: schema\n",
    "\n",
    "\"Autoencoding\" is a data compression algorithm where the compression and decompression functions are 1) data-specific, 2) lossy, and 3) learned automatically from examples rather than engineered by a human. Additionally, in almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks.\n",
    "\n",
    "1. Autoencoders are data-specific, which means that they will only be able to compress data similar to what they have been trained on. This is different from, say, the MPEG-2 Audio Layer III (MP3) compression algorithm, which only holds assumptions about \"sound\" in general, but not about specific types of sounds. An autoencoder trained on pictures of faces would do a rather poor job of compressing pictures of trees, because the features it would learn would be face-specific.\n",
    "\n",
    "2. Autoencoders are lossy, which means that the decompressed outputs will be degraded compared to the original inputs (similar to MP3 or JPEG compression). This differs from lossless arithmetic compression.\n",
    "\n",
    "3. Autoencoders are learned automatically from data examples, which is a useful property: it means that it is easy to train specialized instances of the algorithm that will perform well on a specific type of input. It doesn't require any new engineering, just appropriate training data.\n",
    "\n",
    "To build an autoencoder, you need three things: an encoding function, a decoding function, and a distance function between the amount of information loss between the compressed representation of your data and the decompressed representation (i.e. a \"loss\" function). The encoder and decoder will be chosen to be parametric functions (typically neural networks), and to be differentiable with respect to the distance function, so the parameters of the encoding/decoding functions can be optimize to minimize the reconstruction loss, using Stochastic Gradient Descent. It's simple! And you don't even need to understand any of these words to start using autoencoders in practice.\n",
    "\n",
    "## Are they good at data compression?\n",
    "Usually, not really. In picture compression for instance, it is pretty difficult to train an autoencoder that does a better job than a basic algorithm like JPEG, and typically the only way it can be achieved is by restricting yourself to a very specific type of picture (e.g. one for which JPEG does not do a good job). The fact that autoencoders are data-specific makes them generally impractical for real-world data compression problems: you can only use them on data that is similar to what they were trained on, and making them more general thus requires lots of training data. But future advances might change this, who knows.\n",
    "\n",
    "## What are autoencoders good for?\n",
    "They are rarely used in practical applications. In 2012 they briefly found an application in greedy layer-wise pretraining for deep convolutional neural networks [1], but this quickly fell out of fashion as we started realizing that better random weight initialization schemes were sufficient for training deep networks from scratch. In 2014, batch normalization [2] started allowing for even deeper networks, and from late 2015 we could train arbitrarily deep networks from scratch using residual learning [3].\n",
    "\n",
    "Today two interesting practical applications of autoencoders are data denoising (which we feature later in this post), and dimensionality reduction for data visualization. With appropriate dimensionality and sparsity constraints, autoencoders can learn data projections that are more interesting than PCA or other basic techniques.\n",
    "\n",
    "For 2D visualization specifically, t-SNE (pronounced \"tee-snee\") is probably the best algorithm around, but it typically requires relatively low-dimensional data. So a good strategy for visualizing similarity relationships in high-dimensional data is to start by using an autoencoder to compress your data into a low-dimensional space (e.g. 32-dimensional), then use t-SNE for mapping the compressed data to a 2D plane. Note that a nice parametric implementation of t-SNE in Keras was developed by Kyle McDonald and is available on Github. Otherwise scikit-learn also has a simple and practical implementation.\n",
    "\n",
    "## So what's the big deal with autoencoders?\n",
    "Their main claim to fame comes from being featured in many introductory machine learning classes available online. As a result, a lot of newcomers to the field absolutely love autoencoders and can't get enough of them. This is the reason why this tutorial exists!\n",
    "\n",
    "Otherwise, one reason why they have attracted so much research and attention is because they have long been thought to be a potential avenue for solving the problem of unsupervised learning, i.e. the learning of useful representations without the need for labels. Then again, autoencoders are not a true unsupervised learning technique (which would imply a different learning process altogether), they are a self-supervised technique, a specific instance of supervised learning where the targets are generated from the input data. In order to get self-supervised models to learn interesting features, you have to come up with an interesting synthetic target and loss function, and that's where problems arise: merely learning to reconstruct your input in minute detail might not be the right choice here. At this point there is significant evidence that focusing on the reconstruction of a picture at the pixel level, for instance, is not conductive to learning interesting, abstract features of the kind that label-supervized learning induces (where targets are fairly abstract concepts \"invented\" by humans such as \"dog\", \"car\"...). In fact, one may argue that the best features in this regard are those that are the worst at exact input reconstruction while achieving high performance on the main task that you are interested in (classification, localization, etc).\n",
    "\n",
    "In self-supervized learning applied to vision, a potentially fruitful alternative to autoencoder-style input reconstruction is the use of toy tasks such as jigsaw puzzle solving, or detail-context matching (being able to match high-resolution but small patches of pictures with low-resolution versions of the pictures they are extracted from). The following paper investigates jigsaw puzzle solving and makes for a very interesting read: Noroozi and Favaro (2016) Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles. Such tasks are providing the model with built-in assumptions about the input data which are missing in traditional autoencoders, such as \"visual macro-structure matters more than pixel-level details\".\n",
    "\n",
    "jigsaw puzzle task\n",
    "\n",
    "Let's build the simplest possible autoencoder\n",
    "We'll start simple, with a single fully-connected neural layer as encoder and as decoder:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Let's also creamte a separate encoder model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now let's train our autoencoder to reconstruct MNIST digits.\n",
    "\n",
    "First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adam optimizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3832 - val_loss: 0.1914\n",
      "Epoch 2/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1813 - val_loss: 0.1535\n",
      "Epoch 3/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1494 - val_loss: 0.1331\n",
      "Epoch 4/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1312 - val_loss: 0.1206\n",
      "Epoch 5/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1195 - val_loss: 0.1121\n",
      "Epoch 6/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1119 - val_loss: 0.1065\n",
      "Epoch 7/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1066 - val_loss: 0.1023\n",
      "Epoch 8/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1028 - val_loss: 0.0991\n",
      "Epoch 9/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0997 - val_loss: 0.0969\n",
      "Epoch 10/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0978 - val_loss: 0.0953\n",
      "Epoch 11/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0962 - val_loss: 0.0943\n",
      "Epoch 12/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0956 - val_loss: 0.0936\n",
      "Epoch 13/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0948 - val_loss: 0.0932\n",
      "Epoch 14/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0943 - val_loss: 0.0928\n",
      "Epoch 15/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0943 - val_loss: 0.0926\n",
      "Epoch 16/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 17/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 18/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 19/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 20/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 21/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0930 - val_loss: 0.0920\n",
      "Epoch 22/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0932 - val_loss: 0.0921\n",
      "Epoch 23/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 24/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 25/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 26/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 27/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 28/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0931 - val_loss: 0.0917\n",
      "Epoch 29/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 30/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 31/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 32/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 33/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
      "Epoch 34/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0929 - val_loss: 0.0916\n",
      "Epoch 35/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 36/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0929 - val_loss: 0.0916\n",
      "Epoch 37/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0928 - val_loss: 0.0915\n",
      "Epoch 38/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 39/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 40/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 41/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0925 - val_loss: 0.0915\n",
      "Epoch 42/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0925 - val_loss: 0.0915\n",
      "Epoch 43/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 44/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 45/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 46/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0924 - val_loss: 0.0915\n",
      "Epoch 47/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0926 - val_loss: 0.0914\n",
      "Epoch 48/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0926 - val_loss: 0.0915\n",
      "Epoch 49/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0927 - val_loss: 0.0914\n",
      "Epoch 50/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0925 - val_loss: 0.0914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21bd114c520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After 50 epochs, the autoencoder seems to reach a stable train/validation loss value of about 0.09. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# Use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Deep autoencoder\n",
    "We do not have to limit ourselves to a single layer as encoder or decoder, we could instead use a stack of layers, such as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_img = keras.Input(shape=(784,))\n",
    "encoded = layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(784, activation='sigmoid')(decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.3484 - val_loss: 0.1773\n",
      "Epoch 2/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1656 - val_loss: 0.1394\n",
      "Epoch 3/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1370 - val_loss: 0.1263\n",
      "Epoch 4/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1258 - val_loss: 0.1188\n",
      "Epoch 5/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1185 - val_loss: 0.1126\n",
      "Epoch 6/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1133 - val_loss: 0.1088\n",
      "Epoch 7/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1093 - val_loss: 0.1061\n",
      "Epoch 8/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1067 - val_loss: 0.1042\n",
      "Epoch 9/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1045 - val_loss: 0.1023\n",
      "Epoch 10/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1028 - val_loss: 0.1005\n",
      "Epoch 11/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1012 - val_loss: 0.0989\n",
      "Epoch 12/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0995 - val_loss: 0.0976\n",
      "Epoch 13/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0982 - val_loss: 0.0966\n",
      "Epoch 14/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0970 - val_loss: 0.0964\n",
      "Epoch 15/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0962 - val_loss: 0.0945\n",
      "Epoch 16/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0953 - val_loss: 0.0940\n",
      "Epoch 17/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0945 - val_loss: 0.0932\n",
      "Epoch 18/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0941 - val_loss: 0.0928\n",
      "Epoch 19/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 20/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 21/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0923 - val_loss: 0.0911\n",
      "Epoch 22/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0918 - val_loss: 0.0908\n",
      "Epoch 23/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0911 - val_loss: 0.0901\n",
      "Epoch 24/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0906 - val_loss: 0.0898\n",
      "Epoch 25/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0901 - val_loss: 0.0893\n",
      "Epoch 26/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0897 - val_loss: 0.0887\n",
      "Epoch 27/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0892 - val_loss: 0.0881\n",
      "Epoch 28/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0890 - val_loss: 0.0879\n",
      "Epoch 29/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0885 - val_loss: 0.0875\n",
      "Epoch 30/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0883 - val_loss: 0.0872\n",
      "Epoch 31/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0879 - val_loss: 0.0874\n",
      "Epoch 32/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0876 - val_loss: 0.0868\n",
      "Epoch 33/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0874 - val_loss: 0.0864\n",
      "Epoch 34/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0869 - val_loss: 0.0863\n",
      "Epoch 35/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0867 - val_loss: 0.0861\n",
      "Epoch 36/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0867 - val_loss: 0.0859\n",
      "Epoch 37/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0866 - val_loss: 0.0857\n",
      "Epoch 38/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0861 - val_loss: 0.0858\n",
      "Epoch 39/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0858 - val_loss: 0.0855\n",
      "Epoch 40/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0858 - val_loss: 0.0852\n",
      "Epoch 41/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0858 - val_loss: 0.0850\n",
      "Epoch 42/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0855 - val_loss: 0.0848\n",
      "Epoch 43/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0852 - val_loss: 0.0847\n",
      "Epoch 44/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0851 - val_loss: 0.0850\n",
      "Epoch 45/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0849 - val_loss: 0.0845\n",
      "Epoch 46/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0847 - val_loss: 0.0843\n",
      "Epoch 47/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.0848 - val_loss: 0.0842\n",
      "Epoch 48/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 0.0845 - val_loss: 0.0840\n",
      "Epoch 49/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0845 - val_loss: 0.0838\n",
      "Epoch 50/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0841 - val_loss: 0.0839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21bd71e13f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Convolutional autoencoder\n",
    "Since our inputs are images, it makes sense to use convolutional neural networks (convnets) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better.\n",
    "\n",
    "Let's implement one. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To train it, we will use the original MNIST digits with shape (samples, 3, 28, 28), and we will just normalize pixel values between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.3249 - val_loss: 0.1516\n",
      "Epoch 2/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1464 - val_loss: 0.1297\n",
      "Epoch 3/50\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.1285 - val_loss: 0.1198\n",
      "Epoch 4/50\n",
      "\u001b[1m175/469\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1202"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Ort\\miniconda3\\envs\\keras_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
