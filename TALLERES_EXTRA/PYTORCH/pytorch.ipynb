{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Python Tutorial: Solving MNIST with Keras and PyTorch\n",
    "\n",
    "In this tutorial, we will explore how to solve the MNIST handwritten digit classification problem using different approaches. We will start with simple dense (fully connected) layers in Keras, then move to Convolutional Neural Networks (CNNs) in Keras. After that, we will transition to PyTorch, where we will implement dense layers and CNNs, and finally, we will enhance our PyTorch CNN model with data augmentation.\n",
    "\n",
    "The narrative will follow a progression where each approach builds upon the previous one, highlighting the differences between Keras and PyTorch, and explaining why certain choices are made. By the end of this tutorial, you will have a deep understanding of how to implement and improve neural networks for image classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. MNIST using Keras Dense Layers\n",
    "\n",
    "### Introduction to MNIST\n",
    "The MNIST dataset consists of 28x28 grayscale images of handwritten digits (0-9). The goal is to classify each image into one of the 10 classes.\n",
    "\n",
    "### Why Start with Dense Layers?\n",
    "Dense layers are the simplest type of neural network layers, where each neuron is connected to every neuron in the previous layer. Starting with dense layers allows us to understand the basics of neural networks before moving to more complex architectures like CNNs.\n",
    "\n",
    "### Step-by-Step Implementation\n",
    "\n",
    "#### 1.1 Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Loading and Preprocessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Flatten the 28x28 images into 784-dimensional vectors\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1.3 Building the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Input((28*28,)))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1.4 Compiling the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adamw',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1.5 Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8228 - loss: 0.6237 - val_accuracy: 0.9623 - val_loss: 0.1390\n",
      "Epoch 2/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.1827 - val_accuracy: 0.9718 - val_loss: 0.1005\n",
      "Epoch 3/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9628 - loss: 0.1252 - val_accuracy: 0.9782 - val_loss: 0.0833\n",
      "Epoch 4/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9709 - loss: 0.0976 - val_accuracy: 0.9772 - val_loss: 0.0749\n",
      "Epoch 5/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0812 - val_accuracy: 0.9800 - val_loss: 0.0700\n",
      "Epoch 6/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0687 - val_accuracy: 0.9813 - val_loss: 0.0632\n",
      "Epoch 7/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0572 - val_accuracy: 0.9798 - val_loss: 0.0666\n",
      "Epoch 8/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0511 - val_accuracy: 0.9800 - val_loss: 0.0642\n",
      "Epoch 9/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0437 - val_accuracy: 0.9805 - val_loss: 0.0668\n",
      "Epoch 10/10\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0396 - val_accuracy: 0.9818 - val_loss: 0.0632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22665bd6b00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(train_images, train_labels, validation_split=0.1, epochs=10, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.6 Evaluating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0766\n",
      "Test accuracy: 0.9791\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Discussion\n",
    "- **Pros**: Simple to implement, good for understanding the basics.\n",
    "- **Cons**: Dense layers do not take into account the spatial structure of images, leading to lower accuracy compared to CNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. MNIST using Keras CNN Layers\n",
    "\n",
    "### Why Move to CNNs?\n",
    "Convolutional Neural Networks (CNNs) are designed to work with image data. They use convolutional layers to extract spatial features, making them more effective for image classification tasks.\n",
    "\n",
    "### Step-by-Step Implementation\n",
    "\n",
    "#### 2.1 Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2.2 Loading and Preprocessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Reshape the images to include a single channel (grayscale)\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#### 2.3 Building the Model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Input((28,28,1)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2.4 Compiling the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adamw',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2.5 Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.8561 - loss: 0.4689 - val_accuracy: 0.9852 - val_loss: 0.0505\n",
      "Epoch 2/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0549 - val_accuracy: 0.9890 - val_loss: 0.0398\n",
      "Epoch 3/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0345 - val_accuracy: 0.9878 - val_loss: 0.0419\n",
      "Epoch 4/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0298 - val_accuracy: 0.9923 - val_loss: 0.0302\n",
      "Epoch 5/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0229 - val_accuracy: 0.9903 - val_loss: 0.0368\n",
      "Epoch 6/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0185 - val_accuracy: 0.9907 - val_loss: 0.0384\n",
      "Epoch 7/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.0171 - val_accuracy: 0.9895 - val_loss: 0.0402\n",
      "Epoch 8/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9960 - loss: 0.0131 - val_accuracy: 0.9928 - val_loss: 0.0350\n",
      "Epoch 9/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0090 - val_accuracy: 0.9918 - val_loss: 0.0341\n",
      "Epoch 10/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9973 - loss: 0.0094 - val_accuracy: 0.9928 - val_loss: 0.0293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22665fd7940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(train_images, train_labels, validation_split=0.1, epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2.6 Evaluating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0402\n",
      "Test accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Discussion\n",
    "- **Pros**: CNNs capture spatial features, leading to higher accuracy.\n",
    "- **Cons**: More complex to implement and computationally expensive compared to dense layers.\n",
    "\n",
    "## 3. MNIST using PyTorch Dense Layers\n",
    "\n",
    "### Why Transition to PyTorch?\n",
    "PyTorch is a powerful deep learning framework that offers more flexibility and control compared to Keras. It is particularly popular in research due to its dynamic computation graph.\n",
    "\n",
    "### Step-by-Step Implementation\n",
    "\n",
    "#### 3.1 Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 3.2 Loading and Preprocessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# === 3. Perform 90-10 Split ===\n",
    "train_size = int(0.9 * len(full_train_dataset))  # 90% for training\n",
    "val_size = len(full_train_dataset) - train_size  # 10% for validation\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)  # No shuffle for validation\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## **Step 1: Data Transformation**\n",
    "```python\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "```\n",
    "### **What is happening here?**\n",
    "- The `transform` variable defines a sequence of transformations that will be applied to the MNIST images before they are fed into the model.\n",
    "- `transforms.Compose([...])`: Combines multiple transformations into one pipeline.\n",
    "- `transforms.ToTensor()`: Converts the images from PIL images (or NumPy arrays) into **PyTorch tensors** with values in **[0,1]**.\n",
    "- `transforms.Normalize((0.5,), (0.5,))`: Normalizes the pixel values using the formula:\n",
    "  \n",
    "  \\[\n",
    "  X_{\\text{normalized}} = \\frac{X - \\text{mean}}{\\text{std}}\n",
    "  \\]\n",
    "  \n",
    "  Since MNIST images have pixel values between 0 and 1, subtracting **0.5** and dividing by **0.5** rescales them into the range **[-1,1]**, which is useful for better training stability.\n",
    "\n",
    "### **Alternative Options**\n",
    "- Instead of `transforms.Normalize((0.5,), (0.5,))`, we could use:\n",
    "  - `transforms.Normalize((0,), (1,))` (no normalization)\n",
    "  - `transforms.RandomRotation(30)`: Rotates images randomly for data augmentation.\n",
    "  - `transforms.RandomAffine(30, translate=(0.1,0.1))`: Adds random translations and rotations.\n",
    "  - `transforms.Grayscale(num_output_channels=1)`: Ensures single-channel grayscale output.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Loading the MNIST Dataset**\n",
    "```python\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "```\n",
    "### **What is happening here?**\n",
    "- `datasets.MNIST(...)` is a **PyTorch dataset class** that automatically downloads and loads the MNIST dataset.\n",
    "- Parameters:\n",
    "  - `root='./data'`: Specifies the directory where the dataset will be stored.\n",
    "  - `train=True`: Loads the **training set** (60,000 images).\n",
    "  - `train=False`: Loads the **test set** (10,000 images).\n",
    "  - `download=True`: Downloads the dataset if it is not already present.\n",
    "  - `transform=transform`: Applies the previously defined transformations.\n",
    "\n",
    "### **Alternative Dataset Options**\n",
    "- Instead of `datasets.MNIST`, we could use:\n",
    "  - `datasets.FashionMNIST`: Similar to MNIST but with clothing images.\n",
    "  - `datasets.CIFAR10`: A dataset with 10 object classes (e.g., dog, cat, car).\n",
    "  - `datasets.ImageFolder(root='path/to/dataset', transform=transform)`: For custom datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Creating Data Loaders**\n",
    "```python\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "```\n",
    "### **What is happening here?**\n",
    "- The `DataLoader` class **creates an iterable (iterator)** over the dataset, allowing **batch processing** and **shuffling**.\n",
    "- Parameters:\n",
    "  - `train_dataset`: The dataset to load.\n",
    "  - `batch_size=128`: The number of samples per batch (128 images per iteration).\n",
    "  - `shuffle=True`: Randomizes the order of the training data at each epoch to prevent overfitting.\n",
    "  - `shuffle=False`: Maintains a fixed order for the test set.\n",
    "\n",
    "### **Alternative `DataLoader` Options**\n",
    "- `batch_size=32` or `batch_size=256`: Smaller batches use less memory but take longer per epoch, larger batches train faster but require more memory.\n",
    "- `num_workers=4`: Uses multiple CPU threads for faster data loading.\n",
    "- `pin_memory=True`: Speeds up GPU training by storing tensors in pinned (page-locked) memory.\n",
    "\n",
    "---\n",
    "\n",
    "## **Comparison with TensorFlow**\n",
    "The equivalent TensorFlow/Keras code would be:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images\n",
    "train_images = (train_images.astype('float32') / 255.0 - 0.5) / 0.5\n",
    "test_images = (test_images.astype('float32') / 255.0 - 0.5) / 0.5\n",
    "\n",
    "# Add a channel dimension (needed for CNNs)\n",
    "train_images = train_images[..., tf.newaxis]\n",
    "test_images = test_images[..., tf.newaxis]\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(60000).batch(128)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(128)\n",
    "```\n",
    "\n",
    "### **Comparison: PyTorch vs TensorFlow**\n",
    "| Feature         | PyTorch (`torchvision`) | TensorFlow (`tf.data`) |\n",
    "|----------------|----------------|----------------|\n",
    "| **Data Loading** | `datasets.MNIST(root, download=True)` | `mnist.load_data()` (built-in) |\n",
    "| **Transformations** | `transforms.Compose([...])` | Manual NumPy preprocessing |\n",
    "| **Normalization** | `transforms.Normalize((0.5,), (0.5,))` | `image = (image / 255.0 - 0.5) / 0.5` |\n",
    "| **Batching & Shuffling** | `DataLoader(dataset, batch_size, shuffle=True)` | `Dataset.shuffle().batch()` |\n",
    "| **Customization** | More flexible for custom datasets | Easier integration with TF models |\n",
    "\n",
    "### **Which is better?**\n",
    "- **PyTorch**: More flexible, better for research and debugging.\n",
    "- **TensorFlow**: More optimized for production and deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 3.3 Building the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = DenseNet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Understanding the PyTorch Code**\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DenseNet(nn.Module):  # (1)\n",
    "    def __init__(self):  # (2)\n",
    "        super(DenseNet, self).__init__()  # (3)\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)  # (4)\n",
    "        self.fc2 = nn.Linear(512, 10)  # (5)\n",
    "\n",
    "    def forward(self, x):  # (6)\n",
    "        x = x.view(-1, 28 * 28)  # (7)\n",
    "        x = torch.relu(self.fc1(x))  # (8)\n",
    "        x = self.fc2(x)  # (9)\n",
    "        return x  # (10)\n",
    "\n",
    "model = DenseNet()  # (11)\n",
    "```\n",
    "\n",
    "### **Breaking It Down**\n",
    "1. **Class Definition (`class DenseNet(nn.Module)`)**  \n",
    "   - This is **not** just an arbitrary class. It **inherits** from `nn.Module`, which gives the model its **core properties** (like tracking layers and parameters).\n",
    "   - The decision to use a **class-based approach** reflects PyTorch‚Äôs **object-oriented design philosophy**, which encourages **flexibility, customization, and introspection**.\n",
    "\n",
    "2. **Constructor (`__init__()`)**  \n",
    "   - Defines **what layers exist** in the network.\n",
    "   - Uses `super(DenseNet, self).__init__()` to ensure that `nn.Module` is **properly initialized**.\n",
    "\n",
    "3. **Defining Layers (`self.fc1`, `self.fc2`)**  \n",
    "   - `self.fc1 = nn.Linear(28 * 28, 512)`: A **fully connected layer** that takes **28x28=784** input features (flattened image) and outputs **512** neurons.\n",
    "   - `self.fc2 = nn.Linear(512, 10)`: Maps from **512 neurons** to **10 classes** (digits 0-9).\n",
    "\n",
    "4. **Forward Method (`forward(self, x)`)**  \n",
    "   - This method defines the **actual computation** of the model.\n",
    "   - `x = x.view(-1, 28 * 28)`: Reshapes **2D images** into **1D vectors**.\n",
    "   - `x = torch.relu(self.fc1(x))`: Passes through **ReLU activation**.\n",
    "   - `x = self.fc2(x)`: No activation function here‚Äîthis is raw **logits**.\n",
    "\n",
    "---\n",
    "\n",
    "## **How is this Different from TensorFlow‚Äôs Sequential API?**\n",
    "\n",
    "A similar **TensorFlow model** using `Sequential`:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "```\n",
    "\n",
    "### **Key Differences:**\n",
    "| Feature            | PyTorch `nn.Module` (Class)  | TensorFlow `Sequential` (API) |\n",
    "|--------------------|----------------------------|------------------------------|\n",
    "| **Flexibility**    | Highly flexible (OOP-based) | Limited to stackable layers |\n",
    "| **Extensibility**  | Can define custom layers, forward passes, and complex architectures | Harder to customize beyond simple stacks |\n",
    "| **Explicit Forward Pass** | Uses `forward(self, x)`, explicitly defining computations | Automatically handles `call()` method |\n",
    "| **Parameter Handling** | `self.fc1`, `self.fc2` are attributes (trackable via `model.parameters()`) | Hidden inside `model.layers[]` |\n",
    "| **Best Use Case**  | Research, complex architectures, and debugging | Standard feedforward and CNN models |\n",
    "\n",
    "### **Philosophical Difference**\n",
    "- **TensorFlow‚Äôs `Sequential` is high-level**:  \n",
    "  - It‚Äôs declarative: **‚ÄúJust tell me what layers you want, and I‚Äôll handle the execution.‚Äù**\n",
    "  - It follows a \"write less, do more\" approach.\n",
    "  - Great for quick prototyping.\n",
    "  \n",
    "- **PyTorch‚Äôs `nn.Module` is explicit and imperative**:  \n",
    "  - It‚Äôs more like **manual control over computation**.\n",
    "  - The `forward()` method means we‚Äôre **not just stacking layers**‚Äîwe have **complete control over how data flows**.\n",
    "  - This makes PyTorch **more flexible** for architectures like:\n",
    "    - **Skip connections** (e.g., ResNets)\n",
    "    - **Multiple inputs/outputs**\n",
    "    - **Graph-based computations** (e.g., transformers)\n",
    "\n",
    "---\n",
    "\n",
    "## **Why a Class? Why Inherit from `nn.Module`?**\n",
    "1. **State Management**  \n",
    "   - Inheriting from `nn.Module` **automatically tracks** all layers and parameters.\n",
    "   - This is why calling `model.parameters()` works effortlessly.\n",
    "\n",
    "2. **Reusability & Encapsulation**  \n",
    "   - We can **extend** this class for **custom architectures**.\n",
    "   - Example:\n",
    "     ```python\n",
    "     class CustomDenseNet(DenseNet):\n",
    "         def __init__(self):\n",
    "             super().__init__()\n",
    "             self.fc3 = nn.Linear(10, 5)  # Extra layer\n",
    "\n",
    "         def forward(self, x):\n",
    "             x = super().forward(x)\n",
    "             return self.fc3(x)\n",
    "     ```\n",
    "   - This is **impossible** in TensorFlow‚Äôs `Sequential`.\n",
    "\n",
    "3. **Explicit Forward Pass**  \n",
    "   - PyTorch‚Äôs philosophy emphasizes **explicit computation graphs** (dynamic computation).\n",
    "   - Unlike TensorFlow (which builds static graphs), **PyTorch allows different forward passes per call**.\n",
    "\n",
    "4. **Custom Behaviors Beyond `Sequential`**  \n",
    "   - We could add:\n",
    "     - **Custom activations** (beyond ReLU).\n",
    "     - **Multiple forward passes** (e.g., stochastic forward).\n",
    "     - **Conditionally executed layers** (e.g., if-else logic inside `forward()`).\n",
    "\n",
    "---\n",
    "\n",
    "## **What Other Methods & Arguments Could This Class Have?**\n",
    "PyTorch `nn.Module` is a base class that supports additional functionality:\n",
    "\n",
    "### **1. Custom Weight Initialization**\n",
    "```python\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_weights)\n",
    "```\n",
    "\n",
    "### **2. Saving & Loading Models**\n",
    "```python\n",
    "torch.save(model.state_dict(), \"model.pth\")  # Save\n",
    "model.load_state_dict(torch.load(\"model.pth\"))  # Load\n",
    "```\n",
    "\n",
    "### **3. Custom Loss Functions**\n",
    "```python\n",
    "class CustomLoss(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.mean((y_pred - y_true) ** 2)  # Example: MSE Loss\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **The Big Takeaway:**\n",
    "- **TensorFlow abstracts away details**:  \n",
    "  - Encourages high-level modeling (great for production-ready code).\n",
    "  - `Sequential` is **declarative**‚Äîless control over how computations happen.\n",
    "  \n",
    "- **PyTorch exposes raw control**:  \n",
    "  - Makes **execution explicit** (`forward()`).\n",
    "  - Encourages **custom architectures** that break traditional stacks.\n",
    "  - Best suited for **researchers, experimental architectures, and debugging**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 3.4 Defining the Loss Function and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TensorFlow Losses vs. PyTorch Counterparts**\n",
    "| **TensorFlow (Keras)**                          | **PyTorch Equivalent**                              | **Use Case** |\n",
    "|-------------------------------------------------|-----------------------------------------------------|--------------|\n",
    "| `categorical_crossentropy`                      | `nn.CrossEntropyLoss()`                             | Multi-class classification (one-hot labels in TF, class indices in PyTorch) |\n",
    "| `sparse_categorical_crossentropy`               | `nn.CrossEntropyLoss()`                             | Multi-class classification (class indices in both TF and PyTorch) |\n",
    "| `binary_crossentropy`                           | `nn.BCEWithLogitsLoss()` (`nn.BCELoss()` rarely used) | Binary classification (sigmoid + loss in one step) |\n",
    "| `mean_squared_error (mse)`                      | `nn.MSELoss()`                                      | Regression (continuous targets) |\n",
    "| `mean_absolute_error (mae)`                     | `nn.L1Loss()`                                       | Regression (absolute error) |\n",
    "\n",
    "### **Key Differences**\n",
    "1. **No One-Hot Encoding Needed in PyTorch for Classification**\n",
    "   - In TensorFlow, `categorical_crossentropy` expects **one-hot-encoded labels**.\n",
    "   - In PyTorch, `CrossEntropyLoss` expects **integer class labels (0,1,2...)**, not one-hot encoding.\n",
    "   - If using one-hot labels in PyTorch, convert them using `torch.argmax(y, dim=1)`.\n",
    "\n",
    "2. **`BCEWithLogitsLoss()` vs. `BCELoss()`**\n",
    "   - `BCEWithLogitsLoss()` includes **sigmoid activation internally**, so it‚Äôs numerically more stable.\n",
    "   - `BCELoss()` assumes the inputs are already passed through `sigmoid()`, so it‚Äôs rarely used.\n",
    "\n",
    "---\n",
    "\n",
    "## **How to Use These Losses in PyTorch**\n",
    "\n",
    "### **1. Multi-Class Classification (Categorical Crossentropy)**\n",
    "#### **TensorFlow:**\n",
    "```python\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "```\n",
    "#### **PyTorch Equivalent:**\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "```\n",
    "#### **Example Usage in PyTorch:**\n",
    "```python\n",
    "logits = model(images)  # Model output (raw scores, NOT softmax)\n",
    "loss = criterion(logits, labels)  # Labels are class indices (e.g., tensor([0, 2, 1, ...]))\n",
    "```\n",
    "- No `softmax()` needed, `CrossEntropyLoss()` applies it internally.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Multi-Class Classification (Sparse Categorical Crossentropy)**\n",
    "#### **TensorFlow:**\n",
    "```python\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "```\n",
    "#### **PyTorch Equivalent:**\n",
    "Same as `CrossEntropyLoss()`, since PyTorch does **not** require one-hot encoding.\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, labels)  # Labels are class indices\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Binary Classification (Binary Crossentropy)**\n",
    "#### **TensorFlow:**\n",
    "```python\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "```\n",
    "#### **PyTorch Equivalent:**\n",
    "Use `BCEWithLogitsLoss()` (recommended) or `BCELoss()`.\n",
    "```python\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "```\n",
    "#### **Example Usage in PyTorch:**\n",
    "```python\n",
    "logits = model(images)  # Model output (raw scores)\n",
    "loss = criterion(logits, labels.float())  # Labels should be float (0 or 1)\n",
    "```\n",
    "- If using `BCELoss()`, apply `sigmoid()` first:\n",
    "  ```python\n",
    "  criterion = nn.BCELoss()\n",
    "  loss = criterion(torch.sigmoid(logits), labels.float())\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Regression (Mean Squared Error)**\n",
    "#### **TensorFlow:**\n",
    "```python\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "```\n",
    "#### **PyTorch Equivalent:**\n",
    "```python\n",
    "criterion = nn.MSELoss()\n",
    "```\n",
    "#### **Example Usage in PyTorch:**\n",
    "```python\n",
    "predictions = model(inputs)  # Model output (continuous values)\n",
    "loss = criterion(predictions, targets)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Regression (Mean Absolute Error)**\n",
    "#### **TensorFlow:**\n",
    "```python\n",
    "model.compile(loss=\"mae\", optimizer=\"adam\")\n",
    "```\n",
    "#### **PyTorch Equivalent:**\n",
    "```python\n",
    "criterion = nn.L1Loss()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 3.5 Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = False\n",
    "if simple:\n",
    "\n",
    "    for epoch in range(10):\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 0.4413 | Val Loss: 0.2640 | Val Acc: 0.9213\n",
      "Epoch [2/10] - Train Loss: 0.2293 | Val Loss: 0.1744 | Val Acc: 0.9510\n",
      "Epoch [3/10] - Train Loss: 0.1727 | Val Loss: 0.1371 | Val Acc: 0.9607\n",
      "Epoch [4/10] - Train Loss: 0.1425 | Val Loss: 0.1160 | Val Acc: 0.9668\n",
      "Epoch [5/10] - Train Loss: 0.1266 | Val Loss: 0.1205 | Val Acc: 0.9662\n",
      "Epoch [6/10] - Train Loss: 0.1145 | Val Loss: 0.1086 | Val Acc: 0.9688\n",
      "Epoch [7/10] - Train Loss: 0.1026 | Val Loss: 0.0999 | Val Acc: 0.9713\n",
      "Epoch [8/10] - Train Loss: 0.1002 | Val Loss: 0.1022 | Val Acc: 0.9697\n",
      "Epoch [9/10] - Train Loss: 0.0875 | Val Loss: 0.0928 | Val Acc: 0.9747\n",
      "Epoch [10/10] - Train Loss: 0.0840 | Val Loss: 0.0942 | Val Acc: 0.9742\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        outputs = model(batch_X)  # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            outputs = model(batch_X)  # Get predictions\n",
    "            loss = criterion(outputs, batch_y)  # Compute validation loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class (argmax over class dimension)\n",
    "            preds = torch.argmax(outputs, dim=1)  # Convert logits to class indices\n",
    "\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Why Use `torch.no_grad()` During Validation?**\n",
    "\n",
    "When performing validation (or inference), we **do not need to compute gradients** because:\n",
    "1. **We are not updating the model‚Äôs parameters** (weights remain frozen).\n",
    "2. **It reduces memory usage** by preventing PyTorch from storing intermediate computations needed for backpropagation.\n",
    "3. **It speeds up inference** since gradient tracking adds computational overhead.\n",
    "\n",
    "\n",
    "## **How Gradient Computation Works in PyTorch**\n",
    "During training, PyTorch tracks all tensor operations involving model parameters to compute **gradients during backpropagation**. This tracking:\n",
    "- Stores intermediate activations and gradients in memory.\n",
    "- Allows `loss.backward()` to compute **parameter updates**.\n",
    "\n",
    "However, during validation, we only **evaluate** the model, so:\n",
    "- **Gradients are unnecessary**.\n",
    "- **Saving memory is crucial**, especially for large models.\n",
    "\n",
    "\n",
    "## **When Should You Use `torch.no_grad()`?**\n",
    "- **Validation and testing** (e.g., after every epoch).\n",
    "- **Inference/predictions** on new data.\n",
    "- **Feature extraction** (e.g., using pre-trained models without modifying weights).\n",
    "\n",
    "üöÄ **Want an example of how much `torch.no_grad()` saves memory/time in practice?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 3.6 Evaluating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.61%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Discussion\n",
    "- **Pros**: PyTorch offers more flexibility and control over the model and training process.\n",
    "- **Cons**: More verbose and requires a deeper understanding of neural networks compared to Keras.\n",
    "\n",
    "## 4. MNIST using PyTorch CNN Layers\n",
    "\n",
    "### Why Use CNNs in PyTorch?\n",
    "CNNs are more effective for image data, and implementing them in PyTorch allows for greater customization and optimization.\n",
    "\n",
    "### Step-by-Step Implementation\n",
    "\n",
    "#### 4.1 Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 4.2 Loading and Preprocessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "full_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# === 3. Perform 90-10 Split ===\n",
    "train_size = int(0.9 * len(full_train_dataset))  # 90% for training\n",
    "val_size = len(full_train_dataset) - train_size  # 10% for validation\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)  # No shuffle for validation\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 4.3 Building the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 3 * 3)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 4.4 Defining the Loss Function and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 4.5 Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 0.2779 | Val Loss: 0.0755 | Val Acc: 0.9758\n",
      "Epoch [2/10] - Train Loss: 0.0610 | Val Loss: 0.0493 | Val Acc: 0.9848\n",
      "Epoch [3/10] - Train Loss: 0.0420 | Val Loss: 0.0458 | Val Acc: 0.9862\n",
      "Epoch [4/10] - Train Loss: 0.0330 | Val Loss: 0.0367 | Val Acc: 0.9885\n",
      "Epoch [5/10] - Train Loss: 0.0251 | Val Loss: 0.0353 | Val Acc: 0.9893\n",
      "Epoch [6/10] - Train Loss: 0.0206 | Val Loss: 0.0384 | Val Acc: 0.9882\n",
      "Epoch [7/10] - Train Loss: 0.0185 | Val Loss: 0.0424 | Val Acc: 0.9887\n",
      "Epoch [8/10] - Train Loss: 0.0156 | Val Loss: 0.0363 | Val Acc: 0.9897\n",
      "Epoch [9/10] - Train Loss: 0.0131 | Val Loss: 0.0364 | Val Acc: 0.9895\n",
      "Epoch [10/10] - Train Loss: 0.0114 | Val Loss: 0.0577 | Val Acc: 0.9862\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for epoch in range(5):\n",
    "#     for images, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        outputs = model(batch_X)  # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            outputs = model(batch_X)  # Get predictions\n",
    "            loss = criterion(outputs, batch_y)  # Compute validation loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class (argmax over class dimension)\n",
    "            preds = torch.argmax(outputs, dim=1)  # Convert logits to class indices\n",
    "\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 4.6 Evaluating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.83%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Discussion\n",
    "- **Pros**: CNNs in PyTorch are highly customizable and can achieve state-of-the-art performance.\n",
    "- **Cons**: More complex to implement and requires a deeper understanding of both CNNs and PyTorch.\n",
    "\n",
    "## 5. MNIST using PyTorch CNN Layers with Data Augmentation\n",
    "\n",
    "### Why Use Data Augmentation?\n",
    "Data augmentation is a technique used to artificially increase the size of the training dataset by applying random transformations to the images. This helps the model generalize better and reduces overfitting.\n",
    "\n",
    "### Step-by-Step Implementation\n",
    "\n",
    "#### 5.1 Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 5.2 Loading and Preprocessing the Data with Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 54000 | Val samples: 6000 | Test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "# 1) Define Augmentation and Basic Transforms\n",
    "transform_aug = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform_basic = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 2) Determine Train/Val Indices (No Transform Yet)\n",
    "#    We only need the length of the dataset here, not the actual images.\n",
    "dummy_mnist = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "total_size = len(dummy_mnist)\n",
    "train_size = int(0.9 * total_size)  # 90% for training\n",
    "val_size = total_size - train_size  # 10% for validation\n",
    "\n",
    "# Split indices (no overlap)\n",
    "train_indices, val_indices = random_split(\n",
    "    range(total_size),\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    ")\n",
    "\n",
    "# 3) Create Two MNIST Datasets: One Augmented, One Plain\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform_aug)\n",
    "val_dataset   = datasets.MNIST(root='./data', train=True, transform=transform_basic)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, transform=transform_basic)\n",
    "\n",
    "# 4) Create DataLoaders Using SubsetRandomSampler\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(train_indices),\n",
    "    num_workers=2\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(val_indices),\n",
    "    num_workers=2\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_indices)} | Val samples: {len(val_indices)} | Test samples: {len(test_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 5.3 Building the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 3 * 3)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5.4 Defining the Loss Function and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 5.5 Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Train Loss: 0.4503 | Val Loss: 0.0920 | Val Acc: 0.9732\n",
      "Epoch [2/10] - Train Loss: 0.1163 | Val Loss: 0.0564 | Val Acc: 0.9823\n",
      "Epoch [3/10] - Train Loss: 0.0813 | Val Loss: 0.0553 | Val Acc: 0.9833\n",
      "Epoch [4/10] - Train Loss: 0.0674 | Val Loss: 0.0816 | Val Acc: 0.9753\n",
      "Epoch [5/10] - Train Loss: 0.0597 | Val Loss: 0.0440 | Val Acc: 0.9865\n",
      "Epoch [6/10] - Train Loss: 0.0502 | Val Loss: 0.0358 | Val Acc: 0.9887\n",
      "Epoch [7/10] - Train Loss: 0.0475 | Val Loss: 0.0298 | Val Acc: 0.9893\n",
      "Epoch [8/10] - Train Loss: 0.0441 | Val Loss: 0.0320 | Val Acc: 0.9903\n",
      "Epoch [9/10] - Train Loss: 0.0398 | Val Loss: 0.0460 | Val Acc: 0.9862\n",
      "Epoch [10/10] - Train Loss: 0.0385 | Val Loss: 0.0358 | Val Acc: 0.9888\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "\n",
    "        outputs = model(batch_X)  # Forward pass\n",
    "        loss = criterion(outputs, batch_y)  # Compute loss\n",
    "\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            outputs = model(batch_X)  # Get predictions\n",
    "            loss = criterion(outputs, batch_y)  # Compute validation loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class (argmax over class dimension)\n",
    "            preds = torch.argmax(outputs, dim=1)  # Convert logits to class indices\n",
    "\n",
    "            correct += (preds == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5.6 Evaluating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 99.13%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Discussion\n",
    "- **Pros**: Data augmentation helps the model generalize better and reduces overfitting.\n",
    "- **Cons**: Requires more computational resources and careful tuning of augmentation parameters.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this tutorial, we started with a simple dense layer model in Keras, moved to CNNs in Keras, and then transitioned to PyTorch, where we implemented dense layers and CNNs. Finally, we enhanced our PyTorch CNN model with data augmentation. Each step built upon the previous one, highlighting the differences between Keras and PyTorch, and explaining why certain choices were made.\n",
    "\n",
    "By following this tutorial, you should now have a solid understanding of how to implement and improve neural networks for image classification tasks using both Keras and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_environ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
