{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch & Pipelines\n",
    "GridSearch is an optimization tool that we use when tuning hyperparameters. We define the grid of parameters that we want to search through, and we select the best combination of parameters for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 1\n",
    "Itera un algoritmo sobre un conjunto de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3920"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4*7*7*2*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.1, 0.5, 1, 5, 10, 100],\n",
       "                         'degree': [1, 2, 3, 4, 5, 6, 7],\n",
       "                         'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'rbf', 'sigmoid', 'poly']})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid', 'poly'],\n",
    "    'C': [0.001, 0.1, 0.5, 1, 5, 10, 100],\n",
    "    'degree': [1,2,3,4,5,6,7],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "clf = GridSearchCV(estimator = svc,\n",
    "                  param_grid = parameters,\n",
    "                  n_jobs = -1,\n",
    "                  cv = 10)\n",
    "\n",
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, degree=2, gamma='auto', kernel='poly')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.predict(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.93333333, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf = svm.SVC(C=0.1, degree=2, gamma='auto', kernel='poly')\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9866666666666667\n",
      "0.026666666666666658\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(scores))\n",
    "print(np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 2\n",
    "\n",
    "La forma pro es la que hace esto mismo y va recogiendo los errores de entrenamiento, de validación y tiene la capacidad de parar el proceso cuando se requiera además de guardar el modelo en local una vez terminado si es mejor que el que había anteriormente y de cargar el modelo anterior y seguir reentrenando.\n",
    "\n",
    "Para montar un único gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "# Set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.96666667 0.95       0.95       0.95833333 0.24166667\n",
      " 0.89166667 0.95       0.95833333 0.975      0.96666667 0.96666667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('classifier', LinearRegression())]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()],\n",
       "                          'classifier__penalty': ['l1', 'l2']},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__max_features': [1, 2, 3]},\n",
       "                         {'classifier': [SVC(C=5)],\n",
       "                          'classifier__C': [0.001, 0.1, 0.5, 1, 5, 10, 100]}])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('classifier', LinearRegression())\n",
    "])\n",
    "\n",
    "logistic_params = {\n",
    "    'classifier': [LogisticRegression()],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "random_forest_params = {\n",
    "    'classifier': [RandomForestClassifier()],\n",
    "    'classifier__max_features': [1,2,3]\n",
    "}\n",
    "\n",
    "svm_param = {\n",
    "    'classifier': [svm.SVC()],\n",
    "    'classifier__C': [0.001, 0.1, 0.5, 1, 5, 10, 100],\n",
    "}\n",
    "\n",
    "search_space = [\n",
    "    logistic_params,\n",
    "    random_forest_params,\n",
    "    svm_param\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(estimator = pipe,\n",
    "                  param_grid = search_space,\n",
    "                  cv = 10)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0029237 , 0.16714065, 0.59492188, 0.35235133, 0.30766075,\n",
       "        0.00267467, 0.00309877, 0.00263038, 0.00367522, 0.00182283,\n",
       "        0.00218031, 0.00217428]),\n",
       " 'std_fit_time': array([0.00388711, 0.04322333, 0.09178073, 0.0849848 , 0.06129729,\n",
       "        0.00137263, 0.00169853, 0.00116935, 0.00209331, 0.00057809,\n",
       "        0.0016391 , 0.00149634]),\n",
       " 'mean_score_time': array([0.        , 0.001829  , 0.0562362 , 0.01955216, 0.03151882,\n",
       "        0.00162151, 0.00147378, 0.00117435, 0.00084097, 0.00161481,\n",
       "        0.00092642, 0.00144942]),\n",
       " 'std_score_time': array([0.        , 0.00148846, 0.02085135, 0.00973333, 0.01810102,\n",
       "        0.00185684, 0.00152464, 0.0011322 , 0.00031927, 0.00135498,\n",
       "        0.00048209, 0.00137863]),\n",
       " 'param_classifier': masked_array(data=[LogisticRegression(), LogisticRegression(),\n",
       "                    RandomForestClassifier(), RandomForestClassifier(),\n",
       "                    RandomForestClassifier(), SVC(C=5), SVC(C=5), SVC(C=5),\n",
       "                    SVC(C=5), SVC(C=5), SVC(C=5), SVC(C=5)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__penalty': masked_array(data=['l1', 'l2', --, --, --, --, --, --, --, --, --, --],\n",
       "              mask=[False, False,  True,  True,  True,  True,  True,  True,\n",
       "                     True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__max_features': masked_array(data=[--, --, 1, 2, 3, --, --, --, --, --, --, --],\n",
       "              mask=[ True,  True, False, False, False,  True,  True,  True,\n",
       "                     True,  True,  True,  True],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__C': masked_array(data=[--, --, --, --, --, 0.001, 0.1, 0.5, 1, 5, 10, 100],\n",
       "              mask=[ True,  True,  True,  True,  True, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier': LogisticRegression(), 'classifier__penalty': 'l1'},\n",
       "  {'classifier': LogisticRegression(), 'classifier__penalty': 'l2'},\n",
       "  {'classifier': RandomForestClassifier(), 'classifier__max_features': 1},\n",
       "  {'classifier': RandomForestClassifier(), 'classifier__max_features': 2},\n",
       "  {'classifier': RandomForestClassifier(), 'classifier__max_features': 3},\n",
       "  {'classifier': SVC(C=5), 'classifier__C': 0.001},\n",
       "  {'classifier': SVC(C=5), 'classifier__C': 0.1},\n",
       "  {'classifier': SVC(C=5), 'classifier__C': 0.5},\n",
       "  {'classifier': SVC(C=5), 'classifier__C': 1},\n",
       "  {'classifier': SVC(C=5), 'classifier__C': 5},\n",
       "  {'classifier': SVC(C=5), 'classifier__C': 10},\n",
       "  {'classifier': SVC(C=5), 'classifier__C': 100}],\n",
       " 'split0_test_score': array([       nan, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.33333333, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " 'split1_test_score': array([       nan, 0.91666667, 0.83333333, 0.83333333, 0.91666667,\n",
       "        0.16666667, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.91666667, 1.        ]),\n",
       " 'split2_test_score': array([       nan, 0.91666667, 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.16666667, 0.75      , 0.83333333, 0.91666667, 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " 'split3_test_score': array([       nan, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.16666667, 0.91666667, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " 'split4_test_score': array([nan, 1. , 1. , 1. , 1. , 0.5, 1. , 1. , 1. , 1. , 1. , 1. ]),\n",
       " 'split5_test_score': array([       nan, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.25      , 0.83333333, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " 'split6_test_score': array([       nan, 1.        , 0.91666667, 0.91666667, 0.91666667,\n",
       "        0.33333333, 0.83333333, 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.91666667]),\n",
       " 'split7_test_score': array([       nan, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
       "        0.16666667, 0.66666667, 0.75      , 0.83333333, 0.91666667,\n",
       "        0.83333333, 0.83333333]),\n",
       " 'split8_test_score': array([       nan, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.16666667, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        ]),\n",
       " 'split9_test_score': array([       nan, 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.16666667, 1.        , 1.        , 0.91666667, 0.91666667,\n",
       "        0.91666667, 0.91666667]),\n",
       " 'mean_test_score': array([       nan, 0.96666667, 0.95      , 0.95      , 0.95833333,\n",
       "        0.24166667, 0.89166667, 0.95      , 0.95833333, 0.975     ,\n",
       "        0.96666667, 0.96666667]),\n",
       " 'std_test_score': array([       nan, 0.05527708, 0.06666667, 0.06666667, 0.0559017 ,\n",
       "        0.10833333, 0.11211353, 0.08498366, 0.0559017 , 0.03818813,\n",
       "        0.05527708, 0.05527708]),\n",
       " 'rank_test_score': array([12,  2,  7,  7,  5, 11, 10,  7,  5,  1,  2,  2])}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier', SVC(C=5))])\n",
      "0.9749999999999999\n",
      "{'classifier': SVC(C=5), 'classifier__C': 5}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(df):\n",
    "    df['columna1'] = SimpleImputer(strategy='mean')\n",
    "    df['columna2'] = SimpleImputer(strategy='median')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"reglog\", LogisticRegression())\n",
    "])\n",
    "reg_log_param = {\n",
    "    \"imputer__strategy\": ['mean', 'median'],\n",
    "    \"reglog__penalty\": ['l1', 'l2'],\n",
    "    \"reglog__C\": np.logspace(0, 4, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df = col_selection(df)\n",
    "    df = normalizer(df)\n",
    "    modelo.fit(df)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_log = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    # (\"funcion\", my_function())\n",
    "    (\"reglog\", LogisticRegression())\n",
    "])\n",
    "\n",
    "reg_log_param = {\n",
    "    \"imputer__strategy\": ['mean', 'median'],\n",
    "    \"reglog__penalty\": ['l1', 'l2'],\n",
    "    \"reglog__C\": np.logspace(0, 4, 10)\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "rand_forest = RandomForestClassifier()\n",
    "rand_forest_param = {\n",
    "    \"n_estimators\": [10, 100, 1000],\n",
    "    \"max_features\": [1,2,3]\n",
    "}\n",
    "\n",
    "\n",
    "svm = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"selectkbest\", SelectKBest()),\n",
    "    (\"svm\", SVC())\n",
    "])\n",
    "\n",
    "svm_param = {\n",
    "    'selectkbest__k': [2, 3, 4],\n",
    "    'svm__kernel': ['linear', 'rbf', 'sigmoid', 'poly'],\n",
    "    'svm__C': [0.001, 0.1, 0.5, 1, 5, 10, 100],\n",
    "    'svm__degree': [1,2,3,4],\n",
    "    'svm__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "\n",
    "gs_reg_log = GridSearchCV(reg_log,\n",
    "                         reg_log_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose = 0,\n",
    "                         n_jobs = -1)\n",
    "\n",
    "gs_rand_forest = GridSearchCV(rand_forest,\n",
    "                         rand_forest_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose = 0,\n",
    "                         n_jobs = -1)\n",
    "\n",
    "gs_svm = GridSearchCV(svm,\n",
    "                         svm_param,\n",
    "                         cv = 10,\n",
    "                         scoring = 'accuracy',\n",
    "                         verbose = 0,\n",
    "                         n_jobs = -1)\n",
    "\n",
    "grids = {\"gs_reg_log\": gs_reg_log,\n",
    "        \"gs_rand_forest\": gs_rand_forest,\n",
    "        \"gs_svm\": gs_svm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "200 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.93333333        nan 0.93333333        nan 0.95833333\n",
      "        nan 0.95833333        nan 0.94166667        nan 0.94166667\n",
      "        nan 0.94166667        nan 0.94166667        nan 0.94166667\n",
      "        nan 0.94166667        nan 0.93333333        nan 0.93333333\n",
      "        nan 0.95833333        nan 0.95833333        nan 0.94166667\n",
      "        nan 0.94166667        nan 0.94166667        nan 0.94166667\n",
      "        nan 0.94166667        nan 0.94166667]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for nombre, grid_search in grids.items():\n",
    "    grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9583333333333334\n",
      "{'imputer__strategy': 'mean', 'reglog__C': 7.742636826811269, 'reglog__penalty': 'l2'}\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
      "                ('reglog', LogisticRegression(C=7.742636826811269))])\n",
      "LogisticRegression(C=7.742636826811269)\n"
     ]
    }
   ],
   "source": [
    "print(gs_reg_log.best_score_)\n",
    "print(gs_reg_log.best_params_)\n",
    "print(gs_reg_log.best_estimator_)\n",
    "print(gs_reg_log.best_estimator_['reglog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333332\n",
      "{'max_features': 2, 'n_estimators': 1000}\n",
      "RandomForestClassifier(max_features=2, n_estimators=1000)\n"
     ]
    }
   ],
   "source": [
    "print(gs_rand_forest.best_score_)\n",
    "print(gs_rand_forest.best_params_)\n",
    "print(gs_rand_forest.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n",
      "{'selectkbest__k': 4, 'svm__C': 5, 'svm__degree': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=4)),\n",
      "                ('svm', SVC(C=5, degree=1, kernel='linear'))])\n",
      "SVC(C=5, degree=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "print(gs_svm.best_score_)\n",
    "print(gs_svm.best_params_)\n",
    "print(gs_svm.best_estimator_)\n",
    "print(gs_svm.best_estimator_['svm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grid</th>\n",
       "      <th>Best score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs_svm</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs_reg_log</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs_rand_forest</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Grid  Best score\n",
       "2          gs_svm    0.966667\n",
       "0      gs_reg_log    0.958333\n",
       "1  gs_rand_forest    0.933333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grids = [(i, j.best_score_) for i, j in grids.items()]\n",
    "\n",
    "best_grids = pd.DataFrame(best_grids, columns=[\"Grid\", \"Best score\"]).sort_values(by=\"Best score\", ascending=False)\n",
    "best_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gs_svm.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gs_reg_log.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gs_rand_forest.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=4)),\n",
       "                ('svm', SVC(C=5, degree=1, kernel='linear'))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, degree=1, kernel='linear')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36666666666666664"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = gs_svm.best_estimator_['svm'].predict(X_test)\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('selectkbest', SelectKBest(k=4)),\n",
       "                ('svm', SVC(C=5, degree=1, kernel='linear'))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_estimator_['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El mejor modelo ha sido\n",
    "best_model = gs_reg_log.best_estimator_\n",
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imputer__strategy': 'mean',\n",
       " 'reglog__C': 7.742636826811269,\n",
       " 'reglog__penalty': 'l2'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_reg_log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El mejor modelo ha sido\n",
    "best_model = gs_reg_log.best_estimator_\n",
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
       "                ('reglog', LogisticRegression(C=7.742636826811269))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_reg_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El mejor modelo ha sido\n",
    "best_model = gs_rand_forest.best_estimator_\n",
    "best_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gs_reg_log.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
       "                ('reglog', LogisticRegression(C=7.742636826811269))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finished_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(best_model, archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'rb') as archivo_entrada:\n",
    "    modelo_importado = pickle.load(archivo_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
       "                ('reglog', LogisticRegression(C=7.742636826811269))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_importado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
       "                ('reglog', LogisticRegression(C=7.742636826811269))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_importado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo_importado.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos escogido modelo gracias a los datos de validación. Ahora habría que entrenar el modelo con TODOS los datos de train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearch\n",
    "El problema que tiene el GridSearchCV es que computacionalmente es muy costoso cuando el espacio dimensional de los hiperparámetros es grande.\n",
    "\n",
    "Mediante el RandomSearch no se prueban todas las combinaciones, sino unas cuantas de manera aleatoria. Funciona bien con datasets con pocas features. Incluso [hay papers](https://www.jmlr.org/papers/v13/bergstra12a.html) que aseguran que es más eficiente RandomSearch frente a GridSearch\n",
    "\n",
    "![imagen](https://miro.medium.com/proxy/1*ZTlQm_WRcrNqL-nLnx6GJA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9583333333333334\n",
      "Best Hyperparameters: {'reglog__penalty': 'l2', 'reglog__C': 21.544346900318832, 'imputer__strategy': 'median'}\n",
      "Best Estimator: Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('reglog', LogisticRegression(C=21.544346900318832))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "260 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "260 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\josel\\anaconda3\\envs\\new_basic_ds\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.93333333        nan 0.94166667        nan 0.94166667\n",
      "        nan 0.94166667 0.95833333 0.94166667 0.93333333        nan\n",
      "        nan        nan 0.94166667        nan        nan 0.95833333\n",
      " 0.94166667 0.93333333 0.94166667        nan        nan        nan\n",
      " 0.93333333 0.93333333        nan        nan 0.94166667        nan\n",
      " 0.94166667 0.95833333        nan        nan 0.94166667        nan\n",
      " 0.95833333 0.94166667 0.94166667        nan        nan        nan\n",
      "        nan        nan 0.94166667 0.94166667        nan        nan\n",
      " 0.94166667        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "reg_log = Pipeline(steps=[\n",
    "                          (\"imputer\",SimpleImputer()),\n",
    "                          (\"scaler\",StandardScaler()),\n",
    "                          (\"reglog\",LogisticRegression())\n",
    "                         ])\n",
    "\n",
    "reg_log_param = {    \n",
    "                 \"imputer__strategy\": ['mean', 'median', 'most_frequent'],\n",
    "                 \"reglog__penalty\": [\"l1\",\"l2\"], \n",
    "                 \"reglog__C\": np.logspace(0, 4, 10)\n",
    "                }\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(reg_log,\n",
    "                           reg_log_param,\n",
    "                           n_iter = 50,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           cv=10)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "print('Best Estimator: %s' % result.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9583333333333334\n",
      "Best Hyperparameters: {'reglog__penalty': 'l2', 'reglog__C': 21.544346900318832, 'imputer__strategy': 'median'}\n",
      "Best Estimator: Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
      "                ('scaler', StandardScaler()),\n",
      "                ('reglog', LogisticRegression(C=21.544346900318832))])\n"
     ]
    }
   ],
   "source": [
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)\n",
    "print('Best Estimator: %s' % result.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"modelo\":filename_model,\n",
    "#             \"notebook\":notebook_name,\n",
    "#             \"accuracy\":accuracy})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1732bae284a8d06ed853deb97b261ca711a69998aeddea0e76e3a1575b80769"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('new_basic_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
