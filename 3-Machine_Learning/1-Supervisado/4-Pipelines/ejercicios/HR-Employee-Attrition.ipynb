{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHn7-mEg__Op"
   },
   "source": [
    "## Ejercicio attrition\n",
    "\n",
    "1. Carga el dataset [attrition de `kaggle`](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset?resource=download) (Hay que loguearse en kaggle y descargar el csv)\n",
    "   1. Clasificacion de si el empleado deja o no la empresa (el target es la columna Attrition).\n",
    "   2. Usaremos TODAS las columnas disponibles del dataset. No hace falta volverse loco con el feature engineering, pero es posible que alguna cosa haya que hacer para poder meter todas las columnas. \n",
    "   \n",
    "2. Prueba todos los métodos de clasificación vistos hasta ahora mediante GridSearchCV (logistic regression, SVM, al menos un metodo de boosting, random forest y MLP). Obligatorio usarlos todos por separado usando pipelines. Se puede hacer todo en sklearn.\n",
    "   1. Hay que reportar la performance de los modelos con al menos: Accuracy, precission, recall, F1-Score y AUC-ROC\n",
    "   2. IMPORTANTE: Comentar cual es el mejor metodo y cual es la mejor metrica para este caso de uso concreto.\n",
    "   \n",
    "3. Utiliza uno de los métodos para sacar la importancia de las variables del modelo escogido.\n",
    "   **¿Qué es?**\n",
    "   Serie de técnicas que asignan puntuaciones a las variables independientes de un modelo predictivo en función de su importancia relativa al realizar una predicción sobre la variable dependiente o target. \n",
    "   IMPORTANTE: Antes de obtener el feature importance siempre hay que evaluar la capacidad predictiva del modelo implementado.\n",
    "   **Tipos**\n",
    "   1. Métodos \"built in\" en modelos intrinsecamente intepretables (ya vistos al estudiar los modelos lineales y los modelos basados en árboles de decision). \n",
    "   2. Permutation importance\n",
    "   3. Drop columns importance\n",
    "   \n",
    "4. Utilizar un ultimo metodo que sea un stacking (ensemble) de al menos 4 de los metodos anteriores. Obtener las metricas anteriores (acc, prec, recall, etc..)\n",
    "   \n",
    "5. Valoracion y comentarios de los resultados obtenidos al final. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2942,
     "status": "ok",
     "timestamp": 1600160561693,
     "user": {
      "displayName": "Clara Piniella",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjZPvtfXzLnQ9Q1a_2oR-Aa6UCX0_HyTfsCraMd=s64",
      "userId": "06217688725952462825"
     },
     "user_tz": -120
    },
    "id": "trrbrcXx__Ov",
    "outputId": "b19676c4-6a3a-49ac-d22f-7ea24747b6ba"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3.breast_cancer_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a62940825390c4fb6d0fa98e018eb2e1591e483b4bca278484486fb09668db57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
