{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "En este notebook vas a ver un ejemplo de los procesos necesarios para realizar un análisis de sentimientos sobre Tweets. Para ello tendremos que seguir los siguientes pasos:\n",
    "1. Conseguir un Corpus: no es más que una base de datos de texto etiquetado\n",
    "2. Limpiar los datos\n",
    "3. Entrenar un modelo con el corpus\n",
    "4. Atacar a la API de Twitter\n",
    "5. Predecir los nuevos Tweets\n",
    "\n",
    "**Estos programas son muy útiles en campañas de marketing, para monitorizar el lanzamiento de un nuevo producto, realizar seguimiento en Twitter de eventos, o simplemente tener monitorizadas ciertas cuentas o hashtags para tener un programa de análisis real time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Corpus\n",
    "Para conseguir el corpus tendremos que registrarnos en la [página del TASS](http://tass.sepln.org/tass_data/download.php), que se trata de una asociación de análisis semántico que encargada de recopilar texto y mantenerlo etiquetado. \n",
    "\n",
    "Para datasets en ingles lo tenemos más fácil ya que con librerías como [TextBlob](https://textblob.readthedocs.io/en/dev/) podemos predecir directamente la polaridad del Tweet, con modelos ya preentrenados. En el caso del castellano necesitamos acudir a un corpus etiquetado para entrenar nuestro modelo.\n",
    "\n",
    "Registrate en el TASS y accede a sus corpus a través de un link que te llegará al correo tras el registro.\n",
    "\n",
    "![imagen](img/tass_register.png)\n",
    "\n",
    "\n",
    "Una vez estes registrado, descárgate el corpus de tweets en español de entrenamiento. En este punto lo ideal es coger un corpus que se adapte lo máximo posible a los tipos de tweets que intentamos predecir, es decir, si queremos predecir tweets sobre política, procurar elegir un corpus que tenga vocabulario de política.\n",
    "\n",
    "En este notebook se va a elegir un corpus genérico con no demasiados registros para aligerar la limpieza y entrenamiento de los modelos.\n",
    "\n",
    "![imagen](img/download_train_spanish.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leemos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('data/general-train-tagged.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7219, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ccifuentes</td>\n",
       "      <td>Salgo de #VeoTV , que día más largoooooo...</td>\n",
       "      <td>2011-12-02T00:47:55</td>\n",
       "      <td>es</td>\n",
       "      <td>NONE</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CarmendelRiego</td>\n",
       "      <td>@PauladeLasHeras No te libraras de ayudar me/n...</td>\n",
       "      <td>2011-12-02T00:49:40</td>\n",
       "      <td>es</td>\n",
       "      <td>NEU</td>\n",
       "      <td>DISAGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CarmendelRiego</td>\n",
       "      <td>@marodriguezb Gracias MAR</td>\n",
       "      <td>2011-12-02T00:57:40</td>\n",
       "      <td>es</td>\n",
       "      <td>P</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mgilguerrero</td>\n",
       "      <td>Off pensando en el regalito Sinde, la que se v...</td>\n",
       "      <td>2011-12-02T02:33:37</td>\n",
       "      <td>es</td>\n",
       "      <td>N+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paurubio</td>\n",
       "      <td>Conozco a alguien q es adicto al drama! Ja ja ...</td>\n",
       "      <td>2011-12-02T02:59:03</td>\n",
       "      <td>es</td>\n",
       "      <td>P+</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             User                                            Content  \\\n",
       "0      ccifuentes        Salgo de #VeoTV , que día más largoooooo...   \n",
       "1  CarmendelRiego  @PauladeLasHeras No te libraras de ayudar me/n...   \n",
       "2  CarmendelRiego                          @marodriguezb Gracias MAR   \n",
       "3    mgilguerrero  Off pensando en el regalito Sinde, la que se v...   \n",
       "4        paurubio  Conozco a alguien q es adicto al drama! Ja ja ...   \n",
       "\n",
       "                  Date Lang Polarity          Type  \n",
       "0  2011-12-02T00:47:55   es     NONE     AGREEMENT  \n",
       "1  2011-12-02T00:49:40   es      NEU  DISAGREEMENT  \n",
       "2  2011-12-02T00:57:40   es        P     AGREEMENT  \n",
       "3  2011-12-02T02:33:37   es       N+     AGREEMENT  \n",
       "4  2011-12-02T02:59:03   es       P+     AGREEMENT  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dict = {\n",
    "    'User': [],\n",
    "    'Content': [],\n",
    "    'Date': [],\n",
    "    'Lang': [],\n",
    "    'Polarity': [],\n",
    "    'Type': []\n",
    "}\n",
    "\n",
    "for i in root.iter('tweet'):\n",
    "    user = i.find('user').text\n",
    "    content = i.find('content').text\n",
    "    date = i.find('date').text\n",
    "    lang = i.find('lang').text\n",
    "    polarity = i.find('sentiments').find('polarity').find('value').text\n",
    "    tweet_type = i.find('sentiments').find('polarity').find('type').text\n",
    "    \n",
    "    raw_dict['User'].append(user)\n",
    "    raw_dict['Content'].append(content)\n",
    "    raw_dict['Date'].append(date)\n",
    "    raw_dict['Lang'].append(lang)\n",
    "    raw_dict['Polarity'].append(polarity)\n",
    "    raw_dict['Type'].append(tweet_type)\n",
    "    \n",
    "df = pd.DataFrame(raw_dict)\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna de polaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NONE', 'NEU', 'P', 'N+', 'P+', 'N'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos los valores unicos de la columna de polaridad\n",
    "df.Polarity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Polarity', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columna de tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'Type', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpieza de datos\n",
    "#### Polaridad\n",
    "Vamos a clasificar los Tweets como buenos o malos, por lo que haremos la siguiente agrupación de la polaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polaridad_fun(x):\n",
    "    if x in ('P', 'P+'):\n",
    "        return 0\n",
    "    elif x in ('N', 'N+'):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P', 'N+', 'P+', 'N'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nos cargamos los NONE y los neutros\n",
    "df = df[~df['Polarity'].isin(['NONE', 'NEU'])]\n",
    "df['Polarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasamos la columna a 1s y 0s. Y el tipo\n",
    "df['Polarity'] = df['Polarity'].apply(polaridad_fun)\n",
    "df['Polarity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idioma\n",
    "Nos quedamos con los tweets en español. Si no tuviésemos esa columna podríamos acudir a librerías como `langid` o `langdetect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos los tweets en español\n",
    "df = df[df['Lang'] == 'es']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5066, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos con cuantos registros nos hemos quedado despues del filtrado\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5052, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos los duplicados\n",
    "df.drop_duplicates(subset = 'Content', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signos de puntuación\n",
    "Eliminamos signos de puntuación: puntos, comas, interrogaciones, paréntesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2                            @marodriguezb Gracias MAR\n",
       "3    Off pensando en el regalito Sinde, la que se v...\n",
       "4    Conozco a alguien q es adicto al drama! Ja ja ...\n",
       "6    Toca @crackoviadeTV3 . Grabación dl especial N...\n",
       "8    Buen día todos! Lo primero mandar un abrazo gr...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2                             marodriguezb gracias mar\n",
       "3    off pensando en el regalito sinde la que se va...\n",
       "4    conozco a alguien q es adicto al drama ja ja j...\n",
       "6    toca crackoviadetv  grabación dl especial navi...\n",
       "8    buen día todos lo primero mandar un abrazo gra...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "signos = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\¿)|(\\@)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "\n",
    "def signs_tweets(tweet):\n",
    "    return signos.sub('', tweet.lower())\n",
    "\n",
    "df['Content'] = df['Content'].apply(signs_tweets)\n",
    "df['Content'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(df):\n",
    "    return \" \".join(['{link}' if ('http') in word else word for word in df.split()])\n",
    "\n",
    "df['Content'] = df['Content'].apply(remove_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otros\n",
    "Podríamos hacer un preprocesado mucho más fino:\n",
    "1. Hashtags\n",
    "2. Menciones\n",
    "3. Abreviaturas\n",
    "4. Faltas de ortografía\n",
    "5. Risas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelo\n",
    "Para montar el modelo tendremos que seguir los siguientes pasos\n",
    "1. Eliminamos las stopwords\n",
    "2. Aplicamos un stemmer, SnowBall por ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "spanish_stopwords = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df):\n",
    "    return \" \".join([word for word in df.split() if word not in spanish_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lang</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CarmendelRiego</td>\n",
       "      <td>marodriguezb gracias mar</td>\n",
       "      <td>2011-12-02T00:57:40</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mgilguerrero</td>\n",
       "      <td>off pensando regalito sinde va sgae van corrup...</td>\n",
       "      <td>2011-12-02T02:33:37</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paurubio</td>\n",
       "      <td>conozco alguien q adicto drama ja ja ja suena d</td>\n",
       "      <td>2011-12-02T02:59:03</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Carlos_Latre</td>\n",
       "      <td>toca crackoviadetv grabación dl especial navid...</td>\n",
       "      <td>2011-12-02T07:00:50</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nacho_uriarte</td>\n",
       "      <td>buen día primero mandar abrazo grande miguel f...</td>\n",
       "      <td>2011-12-02T07:45:05</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>AGREEMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             User                                            Content  \\\n",
       "2  CarmendelRiego                           marodriguezb gracias mar   \n",
       "3    mgilguerrero  off pensando regalito sinde va sgae van corrup...   \n",
       "4        paurubio    conozco alguien q adicto drama ja ja ja suena d   \n",
       "6    Carlos_Latre  toca crackoviadetv grabación dl especial navid...   \n",
       "8   nacho_uriarte  buen día primero mandar abrazo grande miguel f...   \n",
       "\n",
       "                  Date Lang  Polarity       Type  \n",
       "2  2011-12-02T00:57:40   es         0  AGREEMENT  \n",
       "3  2011-12-02T02:33:37   es         1  AGREEMENT  \n",
       "4  2011-12-02T02:59:03   es         0  AGREEMENT  \n",
       "6  2011-12-02T07:00:50   es         0  AGREEMENT  \n",
       "8  2011-12-02T07:45:05   es         0  AGREEMENT  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'] = df['Content'].apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2                               marodriguezb graci mar\n",
       "3    off pens regalit sind va sga van corrupt inten...\n",
       "4            conozc algui q adict dram ja ja ja suen d\n",
       "6    toc crackoviadetv grabacion dl especial navide...\n",
       "8    buen dia primer mand abraz grand miguel famili...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def spanish_stemmer(x):\n",
    "    stemmer = SnowballStemmer('spanish')\n",
    "    return \" \".join([stemmer.stem(word) for word in x.split()])\n",
    "\n",
    "df['Content'] = df['Content'].apply(spanish_stemmer)\n",
    "df['Content'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccionamos columnas\n",
    "Nos quedamos con las columnas que nos interesan para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Content', 'Polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/output/data_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Montamos Pipeline\n",
    "Modelos que suelen funcionar bien con pocas observaciones y muchas features son la Regresión logística el LinearSVC o Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('cls', LogisticRegression())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 1 , 1.9),\n",
    "    'vect__min_df': (5, 10, 20,50),\n",
    "    'vect__max_features': (500, 1000),\n",
    "    \"cls__penalty\": [\"l1\",\"l2\"], # Regularizaciones L1 y L2.\n",
    "    \"cls__C\": [0.1, 0.5, 1.0, 5.0] # Cuanta regularizacion queremos\n",
    "\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                          parameters,\n",
    "                          cv = 5,\n",
    "                          n_jobs = -1,\n",
    "                          scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "800 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 449, in _check_solver\n",
      "    % (solver, penalty)\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 355, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1344, in fit_transform\n",
      "    raise ValueError(\"max_df corresponds to < documents than min_df\")\n",
      "ValueError: max_df corresponds to < documents than min_df\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 355, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\joblib\\memory.py\", line 352, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1313, in fit_transform\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1264, in _validate_params\n",
      "    check_scalar(self.max_df, \"max_df\", numbers.Real, min_val=0.0, max_val=1.0)\n",
      "  File \"C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1330, in check_scalar\n",
      "    f\"{name} == {x}, must be\"\n",
      "ValueError: max_df == 1.9, must be <= 1.0.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73179324 0.73218889 0.72090294 0.67873843 0.74109626 0.7365418\n",
      " 0.72090294 0.67873843        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73713645 0.73535525 0.72347622 0.67893723 0.75138741 0.74307332\n",
      " 0.72347622 0.67893723        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931349 0.73832202 0.72367306 0.68051983 0.74841692 0.74544662\n",
      " 0.72367306 0.68051983        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73435928 0.73099372 0.72485961 0.68012437 0.74030202 0.73832222\n",
      " 0.72485961 0.68012437        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(ngram_range=(1, 2))),\n",
       "                                       ('cls', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'cls__C': [0.1, 0.5, 1.0, 5.0],\n",
       "                         'cls__penalty': ['l1', 'l2'],\n",
       "                         'vect__max_df': (0.5, 1, 1.9),\n",
       "                         'vect__max_features': (500, 1000),\n",
       "                         'vect__min_df': (5, 10, 20, 50)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(df['Content'], df['Polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'cls__C': 0.5, 'cls__penalty': 'l2', 'vect__max_df': 0.5, 'vect__max_features': 1000, 'vect__min_df': 5}\n",
      "Best acc: 0.7513874117382064\n",
      "Best model: Pipeline(steps=[('vect',\n",
      "                 CountVectorizer(max_df=0.5, max_features=1000, min_df=5,\n",
      "                                 ngram_range=(1, 2))),\n",
      "                ('cls', LogisticRegression(C=0.5))])\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best acc:\", grid_search.best_score_)\n",
    "print(\"Best model:\", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_['cls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/output/finished_model.model', \"wb\") as archivo_salida:\n",
    "    pickle.dump(grid_search.best_estimator_, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicciones\n",
    "Realizar una predicción con un tweet que escojas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/output/finished_model.model', \"rb\") as archivo_entrada:\n",
    "    pipeline_importada = pickle.load(archivo_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_df=0.5, max_features=1000, min_df=5,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('cls', LogisticRegression(C=0.5))])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_importada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leemos el pipeline con el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.Series('El bombardeo de #Gernika por parte de la aviación nazi y fascista fue uno de los episodios más cruentos de la Guerra Civil. 85 años después, recordamos este día y a todas sus víctimas. Porque la memoria es imprescindible para seguir construyendo una sociedad democrática y en paz.')\n",
    "test_clean = pd.DataFrame(text, columns=['content'])\n",
    "\n",
    "# Signos de puntuacion\n",
    "test_clean['content_clean'] = test_clean['content'].apply(signs_tweets)\n",
    "\n",
    "# Eliminamos links\n",
    "test_clean['content_clean'] = test_clean['content_clean'].apply(remove_links)\n",
    "\n",
    "# Nos cargamos stopwords\n",
    "test_clean['content_clean'] = test_clean['content_clean'].apply(remove_stopwords)\n",
    "\n",
    "# Aplicamos el Stemmer\n",
    "test_clean['content_clean'] = test_clean['content_clean'].apply(spanish_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El bombardeo de #Gernika por parte de la aviación nazi y fascista fue uno de los episodios más cruentos de la Guerra Civil. 85 años después, recordamos este día y a todas sus víctimas. Porque la memoria es imprescindible para seguir construyendo una sociedad democrática y en paz.</td>\n",
       "      <td>bombarde #gernik part aviacion nazi fascist episodi cruent guerr civil años despues record dia tod victim memori imprescind segu constru socied democrat paz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                    content  \\\n",
       "0  El bombardeo de #Gernika por parte de la aviación nazi y fascista fue uno de los episodios más cruentos de la Guerra Civil. 85 años después, recordamos este día y a todas sus víctimas. Porque la memoria es imprescindible para seguir construyendo una sociedad democrática y en paz.   \n",
       "\n",
       "                                                                                                                                                  content_clean  \n",
       "0  bombarde #gernik part aviacion nazi fascist episodi cruent guerr civil años despues record dia tod victim memori imprescind segu constru socied democrat paz  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bombarde #gernik part aviacion nazi fascist episodi cruent guerr civil años despues record dia tod victim memori imprescind segu constru socied democrat paz\n",
       "Name: content_clean, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean['content_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El bombardeo de #Gernika por parte de la aviación nazi y fascista fue uno de los episodios más cruentos de la Guerra Civil. 85 años después, recordamos este día y a todas sus víctimas. Porque la memoria es imprescindible para seguir construyendo una sociedad democrática y en paz.</td>\n",
       "      <td>bombarde #gernik part aviacion nazi fascist episodi cruent guerr civil años despues record dia tod victim memori imprescind segu constru socied democrat paz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                    content  \\\n",
       "0  El bombardeo de #Gernika por parte de la aviación nazi y fascista fue uno de los episodios más cruentos de la Guerra Civil. 85 años después, recordamos este día y a todas sus víctimas. Porque la memoria es imprescindible para seguir construyendo una sociedad democrática y en paz.   \n",
       "\n",
       "                                                                                                                                                  content_clean  \\\n",
       "0  bombarde #gernik part aviacion nazi fascist episodi cruent guerr civil años despues record dia tod victim memori imprescind segu constru socied democrat paz   \n",
       "\n",
       "   Polarity  \n",
       "0         1  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipeline_importada.predict(test_clean['content_clean'])\n",
    "test_clean['Polarity'] = pd.Series(predictions)\n",
    "test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Polarity_Pos</th>\n",
       "      <th>Polarity_Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El bombardeo de #Gernika por parte de la aviación nazi y fascista fue uno de los episodios más cruentos de la Guerra Civil. 85 años después, recordamos este día y a todas sus víctimas. Porque la memoria es imprescindible para seguir construyendo una sociedad democrática y en paz.</td>\n",
       "      <td>bombarde #gernik part aviacion nazi fascist episodi cruent guerr civil años despues record dia tod victim memori imprescind segu constru socied democrat paz</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444031</td>\n",
       "      <td>0.555969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                    content  \\\n",
       "0  El bombardeo de #Gernika por parte de la aviación nazi y fascista fue uno de los episodios más cruentos de la Guerra Civil. 85 años después, recordamos este día y a todas sus víctimas. Porque la memoria es imprescindible para seguir construyendo una sociedad democrática y en paz.   \n",
       "\n",
       "                                                                                                                                                  content_clean  \\\n",
       "0  bombarde #gernik part aviacion nazi fascist episodi cruent guerr civil años despues record dia tod victim memori imprescind segu constru socied democrat paz   \n",
       "\n",
       "   Polarity  Polarity_Pos  Polarity_Neg  \n",
       "0         1      0.444031      0.555969  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipeline_importada.predict_proba(test_clean['content_clean'])\n",
    "test_clean['Polarity_Pos'] = pd.Series(predictions[0][0])\n",
    "test_clean['Polarity_Neg'] = pd.Series(predictions[0][1])\n",
    "test_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predicciones con API (EXTRA)\n",
    "#### API de Twitter\n",
    "Lo primero que tenemos que hacer es conseguir nuevos Tweets. Para ello:\n",
    "1. Nos registramos en la [web de desarrolladores de Twitter](https://developer.twitter.com/en/apply-for-access)\n",
    "2. Bajamos el paquete `tweepy` para atacara  la API de Twitter\n",
    "3. Buscamos un Hashtag de tendencia\n",
    "4. Nos logamos y monitorizamos el hastag\n",
    "5. Aplicamos la limpieza a los Tweets\n",
    "6. Predecimos la polaridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "import tweepy  \n",
    "import time\n",
    "import csv\n",
    "\n",
    "import json\n",
    "\n",
    "with open('./credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "    \n",
    "    \n",
    "# Credenciales de la web de desarroladores\n",
    "access_token = credentials['access_token']  \n",
    "access_token_secret = credentials['access_token_secret']  \n",
    "consumer_key = credentials['consumer_key']\n",
    "consumer_secret = credentials['consumer_secret'] \n",
    "\n",
    "# Nos autenticamos en la API\n",
    "try:\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)  \n",
    "    auth.set_access_token(access_token, access_token_secret)  \n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content</th>\n",
       "      <th>author_description</th>\n",
       "      <th>author_followers_count</th>\n",
       "      <th>author_profile_image_url</th>\n",
       "      <th>author_location</th>\n",
       "      <th>author_profile_background_image_url</th>\n",
       "      <th>author_notifications</th>\n",
       "      <th>geo</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>entities</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Libre Pensador</td>\n",
       "      <td>2021-09-21 09:22:58</td>\n",
       "      <td>@MonederoJC @PODEMOS Osea que no hay dinero pa...</td>\n",
       "      <td></td>\n",
       "      <td>1122</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1334813115...</td>\n",
       "      <td>Valencia, España</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canariona🏴‍☠️ 🔻 #YOAPOYOALGOBIERNO🔻</td>\n",
       "      <td>2021-09-21 09:22:55</td>\n",
       "      <td>RT @Cahora: 🌋🌋 Los curiosos colapsan las carre...</td>\n",
       "      <td>🌊CALIPSO🌊</td>\n",
       "      <td>3210</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1430528064...</td>\n",
       "      <td></td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [{'text': 'LaPalma', 'indices': [...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfontso Arroio</td>\n",
       "      <td>2021-09-21 09:22:52</td>\n",
       "      <td>RT @RTVCes: 🔴Es la fantástica explicación que ...</td>\n",
       "      <td>Kirol Kazetaria</td>\n",
       "      <td>1389</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/7457374250...</td>\n",
       "      <td>Euskal Herria</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pepote</td>\n",
       "      <td>2021-09-21 09:22:50</td>\n",
       "      <td>RT @josuefumero: Sigo poniendo vídeos de la er...</td>\n",
       "      <td></td>\n",
       "      <td>86</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/1373363844...</td>\n",
       "      <td>Málaga, España</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [{'text': 'lapalma', 'indices': [...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alejandro Brito</td>\n",
       "      <td>2021-09-21 09:22:48</td>\n",
       "      <td>RT @IGeociencias: Extensión de la colada de la...</td>\n",
       "      <td>Seguidor de Don Darwin, Quien entienda al babu...</td>\n",
       "      <td>155</td>\n",
       "      <td>http://pbs.twimg.com/profile_images/9419753877...</td>\n",
       "      <td>Santa Cruz de Tenerife, España</td>\n",
       "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'hashtags': [{'text': 'LaPalma', 'indices': [...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           author_name          created_at  \\\n",
       "0                       Libre Pensador 2021-09-21 09:22:58   \n",
       "1  Canariona🏴‍☠️ 🔻 #YOAPOYOALGOBIERNO🔻 2021-09-21 09:22:55   \n",
       "2                      Alfontso Arroio 2021-09-21 09:22:52   \n",
       "3                               Pepote 2021-09-21 09:22:50   \n",
       "4                      Alejandro Brito 2021-09-21 09:22:48   \n",
       "\n",
       "                                             content  \\\n",
       "0  @MonederoJC @PODEMOS Osea que no hay dinero pa...   \n",
       "1  RT @Cahora: 🌋🌋 Los curiosos colapsan las carre...   \n",
       "2  RT @RTVCes: 🔴Es la fantástica explicación que ...   \n",
       "3  RT @josuefumero: Sigo poniendo vídeos de la er...   \n",
       "4  RT @IGeociencias: Extensión de la colada de la...   \n",
       "\n",
       "                                  author_description  author_followers_count  \\\n",
       "0                                                                       1122   \n",
       "1                                          🌊CALIPSO🌊                    3210   \n",
       "2                                    Kirol Kazetaria                    1389   \n",
       "3                                                                         86   \n",
       "4  Seguidor de Don Darwin, Quien entienda al babu...                     155   \n",
       "\n",
       "                            author_profile_image_url  \\\n",
       "0  http://pbs.twimg.com/profile_images/1334813115...   \n",
       "1  http://pbs.twimg.com/profile_images/1430528064...   \n",
       "2  http://pbs.twimg.com/profile_images/7457374250...   \n",
       "3  http://pbs.twimg.com/profile_images/1373363844...   \n",
       "4  http://pbs.twimg.com/profile_images/9419753877...   \n",
       "\n",
       "                  author_location  \\\n",
       "0                Valencia, España   \n",
       "1                                   \n",
       "2                   Euskal Herria   \n",
       "3                  Málaga, España   \n",
       "4  Santa Cruz de Tenerife, España   \n",
       "\n",
       "                author_profile_background_image_url  author_notifications  \\\n",
       "0                                              None                 False   \n",
       "1  http://abs.twimg.com/images/themes/theme1/bg.png                 False   \n",
       "2  http://abs.twimg.com/images/themes/theme1/bg.png                 False   \n",
       "3                                              None                 False   \n",
       "4  http://abs.twimg.com/images/themes/theme1/bg.png                 False   \n",
       "\n",
       "    geo coordinates                                           entities place  \n",
       "0  None        None  {'hashtags': [], 'symbols': [], 'user_mentions...  None  \n",
       "1  None        None  {'hashtags': [{'text': 'LaPalma', 'indices': [...  None  \n",
       "2  None        None  {'hashtags': [], 'symbols': [], 'user_mentions...  None  \n",
       "3  None        None  {'hashtags': [{'text': 'lapalma', 'indices': [...  None  \n",
       "4  None        None  {'hashtags': [{'text': 'LaPalma', 'indices': [...  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_dict = {\n",
    "    'author_name': [],\n",
    "    'created_at': [],\n",
    "    'content': [],\n",
    "    'author_description': [],\n",
    "    'author_followers_count': [],\n",
    "    'author_profile_image_url': [],\n",
    "    'author_location': [],\n",
    "    'author_profile_background_image_url': [],\n",
    "    'author_notifications': [],\n",
    "    'geo': [],\n",
    "    'coordinates': [],\n",
    "    'entities': [],\n",
    "    'place': []\n",
    "}\n",
    "\n",
    "# https://docs.tweepy.org/en/latest/api.html#search-methods\n",
    "\n",
    "cursor = tweepy.Cursor(api.search,\n",
    "                      q = \"#lapalma\",\n",
    "                      lang = \"es\",\n",
    "                      since = \"2021-09-20\").items(50)\n",
    "\n",
    "for tweet in cursor:\n",
    "    \n",
    "    raw_dict['author_name'].append(tweet.author.name)\n",
    "    raw_dict['created_at'].append(tweet.created_at)\n",
    "    raw_dict['content'].append(tweet.text)\n",
    "    raw_dict['author_description'].append(tweet.author.description)\n",
    "    raw_dict['author_followers_count'].append(tweet.author.followers_count)\n",
    "    raw_dict['author_profile_image_url'].append(tweet.author.profile_image_url)\n",
    "    raw_dict['author_location'].append(tweet.author.location)\n",
    "    raw_dict['author_profile_background_image_url'].append(tweet.author.profile_background_image_url)\n",
    "    raw_dict['author_notifications'].append(tweet.author.notifications)\n",
    "    raw_dict['geo'].append(tweet.geo)\n",
    "    raw_dict['coordinates'].append(tweet.coordinates)\n",
    "    raw_dict['entities'].append(tweet.entities)\n",
    "    raw_dict['place'].append(tweet.place)\n",
    "    \n",
    "\n",
    "test = pd.DataFrame(raw_dict)\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
